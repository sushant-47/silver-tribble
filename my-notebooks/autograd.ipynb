{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd\n",
    "- Autograd is a automatic differentiation tool used to calculate derivatives (for training Neural Networks) in pytorch.\n",
    "- Autograd is a core component of pytorch that provides automatic differentiation for tensor operations. It enables gradient computation, which is essential for training machine learning modes using optimization algorithms like gradient descent.\n",
    "\n",
    "- Autograd solves the problem of differentiating nested functions using chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "import math;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx at x=55: 110\n"
     ]
    }
   ],
   "source": [
    "# derivative function of y=x**2\n",
    "def dy_dx(x):\n",
    "    return 2*x;\n",
    "x = 55;\n",
    "print(f\"dy/dx at x={x}: {dy_dx(x)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Process of a simple Neural Network:\n",
    "1. Forward Pass - Compute the output of the network given an input.\n",
    "2. Calculate Loss - Calculate the loss function to quantify the error.\n",
    "3. Backward Pass - Compute gradients (partial derivative) of the loss with respect to multiple parameters (weight, bias).\n",
    "4. Update gradients - Adjust the parameters using an optimization algorithm (ex: gradient descent).\n",
    "\n",
    "- Neural networks behave like a nested function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([4.], requires_grad=True) y: tensor([16.], grad_fn=<PowBackward0>)\n",
      "tensor([8.])\n",
      "x: tensor([10.])\n",
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "# Autograd example 1\n",
    "# Leaf tensor/node - Input x, Root tensor/node - Output y=f(x)\n",
    "\n",
    "x = torch.tensor([4], dtype=torch.float32, requires_grad=True);\n",
    "# y=f(x)=x**2\n",
    "y = x**2;\n",
    "print(\"x:\", x, \"y:\", y);\n",
    "\n",
    "# Start calculating dy/dx\n",
    "y.backward(retain_graph=True);\n",
    "# Get dy/dx at x=4\n",
    "print(x.grad);\n",
    "\n",
    "# sets requires_grad to False for x.\n",
    "x.requires_grad_(False);\n",
    "x[0] = 10;\n",
    "print(\"x:\", x);\n",
    "# y.backward();  # not allowed\n",
    "print(x.grad);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([4.], requires_grad=True) y: tensor([16.], grad_fn=<PowBackward0>) z: tensor([-0.2879], grad_fn=<SinBackward0>)\n",
      "tensor([-7.6613])\n"
     ]
    }
   ],
   "source": [
    "# Autograd example 2\n",
    "# Leaf tensor/node - Input x, Root tensor/node - Output z=f(y), Intermediate tensor/node - y=f(x)\n",
    "# In a computational graph, gradients are not automatically computed for intermediated nodes. (pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)\n",
    "\n",
    "x = torch.tensor([4], requires_grad=True, dtype=torch.float32);\n",
    "# y=f(x)=x**2\n",
    "y = x**2;\n",
    "# z=f(y)=sin(y)\n",
    "z = torch.sin(y);\n",
    "\n",
    "print(\"x:\", x, \"y:\", y, \"z:\", z);\n",
    "\n",
    "# Start calculating dz/dx\n",
    "z.backward();\n",
    "# Get dz/dx at x=4\n",
    "print(x.grad);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
