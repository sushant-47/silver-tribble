{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a4df83-da7f-4f6e-8b41-5b8b09737457",
   "metadata": {},
   "source": [
    "#### Modules\n",
    "- A file containing a set of functions that are present by default to be used in an end application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0225136-3b37-4f87-9cbe-21f2d1cde78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of built-in modules\n",
    "\n",
    "help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e490d1e-9cb1-485c-8670-95c07375dfc1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a list of modules whose name or summary contains 'torch'.\n",
      "If there are any, enter a module name to get more help.\n",
      "\n",
      "functorch \n",
      "functorch._C \n",
      "functorch._src \n",
      "functorch._src.aot_autograd \n",
      "functorch._src.eager_transforms \n",
      "functorch._src.make_functional \n",
      "functorch._src.vmap \n",
      "functorch.compile \n",
      "functorch.dim \n",
      "functorch.dim.batch_tensor \n",
      "functorch.dim.delayed_mul_tensor \n",
      "functorch.dim.dim \n",
      "functorch.dim.magic_trace \n",
      "functorch.dim.op_properties \n",
      "functorch.dim.reference \n",
      "functorch.dim.tree_map \n",
      "functorch.dim.wrap_type \n",
      "functorch.einops \n",
      "functorch.einops._parsing - Adapted from https://github.com/arogozhnikov/einops/blob/36c7bb16e57d6e57f8f3050f9e07abdf3f00469f/einops/parsing.py.\n",
      "functorch.einops.rearrange \n",
      "functorch.experimental \n",
      "functorch.experimental.control_flow \n",
      "functorch.experimental.ops \n",
      "torch - The torch package contains data structures for multi-dimensional\n",
      "torch._C \n",
      "torch._VF - This makes the functions in torch._C._VariableFunctions available as\n",
      "torch.__config__ \n",
      "torch.__future__ \n",
      "torch._appdirs - This file is directly from\n",
      "torch._awaits \n",
      "torch._classes \n",
      "torch._compile - APIs related to torch.compile which lazily import torch._dynamo to avoid\n",
      "torch._custom_op \n",
      "torch._custom_op.autograd \n",
      "torch._custom_op.functional \n",
      "torch._custom_op.impl \n",
      "torch._custom_ops \n",
      "torch._decomp \n",
      "torch._decomp.decompositions \n",
      "torch._decomp.decompositions_for_jvp \n",
      "torch._decomp.decompositions_for_rng \n",
      "torch._deploy \n",
      "torch._dispatch \n",
      "torch._dispatch.python \n",
      "torch._dynamo \n",
      "torch._dynamo._trace_wrapped_higher_order_op \n",
      "torch._dynamo.backends \n",
      "torch._dynamo.backends.common \n",
      "torch._dynamo.backends.cudagraphs \n",
      "torch._dynamo.backends.debugging \n",
      "torch._dynamo.backends.distributed \n",
      "torch._dynamo.backends.inductor \n",
      "torch._dynamo.backends.onnxrt \n",
      "torch._dynamo.backends.registry \n",
      "torch._dynamo.backends.tensorrt - Placeholder for TensorRT backend for dynamo via torch-tensorrt\n",
      "torch._dynamo.backends.torchxla \n",
      "torch._dynamo.backends.tvm \n",
      "torch._dynamo.bytecode_analysis \n",
      "torch._dynamo.bytecode_transformation \n",
      "torch._dynamo.cache_size \n",
      "torch._dynamo.callback \n",
      "torch._dynamo.code_context \n",
      "torch._dynamo.codegen \n",
      "torch._dynamo.compiled_autograd \n",
      "torch._dynamo.comptime \n",
      "torch._dynamo.config \n",
      "torch._dynamo.convert_frame \n",
      "torch._dynamo.current_scope_id \n",
      "torch._dynamo.debug_utils \n",
      "torch._dynamo.decorators \n",
      "torch._dynamo.device_interface \n",
      "torch._dynamo.eval_frame - Functions in this file are responsible for modifying the eval frame\n",
      "torch._dynamo.exc \n",
      "torch._dynamo.external_utils \n",
      "torch._dynamo.funcname_cache \n",
      "torch._dynamo.guards \n",
      "torch._dynamo.hooks \n",
      "torch._dynamo.logging \n",
      "torch._dynamo.mutation_guard \n",
      "torch._dynamo.output_graph \n",
      "torch._dynamo.polyfill - Python polyfills for common builtins.\n",
      "torch._dynamo.profiler \n",
      "torch._dynamo.replay_record \n",
      "torch._dynamo.repro \n",
      "torch._dynamo.repro.after_aot \n",
      "torch._dynamo.repro.after_dynamo \n",
      "torch._dynamo.resume_execution \n",
      "torch._dynamo.side_effects \n",
      "torch._dynamo.source \n",
      "torch._dynamo.symbolic_convert \n",
      "torch._dynamo.tensor_version_op \n",
      "torch._dynamo.test_case \n",
      "torch._dynamo.test_minifier_common \n",
      "torch._dynamo.testing \n",
      "torch._dynamo.trace_rules \n",
      "torch._dynamo.types \n",
      "torch._dynamo.utils \n",
      "torch._dynamo.variables \n",
      "torch._dynamo.variables.base \n",
      "torch._dynamo.variables.builder \n",
      "torch._dynamo.variables.builtin \n",
      "torch._dynamo.variables.constant \n",
      "torch._dynamo.variables.ctx_manager \n",
      "torch._dynamo.variables.dicts \n",
      "torch._dynamo.variables.distributed \n",
      "torch._dynamo.variables.functions \n",
      "torch._dynamo.variables.higher_order_ops \n",
      "torch._dynamo.variables.iter \n",
      "torch._dynamo.variables.lazy \n",
      "torch._dynamo.variables.lists \n",
      "torch._dynamo.variables.misc \n",
      "torch._dynamo.variables.nn_module \n",
      "torch._dynamo.variables.optimizer \n",
      "torch._dynamo.variables.sdpa \n",
      "torch._dynamo.variables.tensor \n",
      "torch._dynamo.variables.torch \n",
      "torch._dynamo.variables.torch_function \n",
      "torch._dynamo.variables.user_defined \n",
      "torch._export \n",
      "torch._export.db \n",
      "torch._export.db.case \n",
      "torch._export.db.examples \n",
      "torch._export.db.examples.assume_constant_result \n",
      "torch._export.db.examples.autograd_function \n",
      "torch._export.db.examples.class_method \n",
      "torch._export.db.examples.cond_branch_class_method \n",
      "torch._export.db.examples.cond_branch_nested_function \n",
      "torch._export.db.examples.cond_branch_nonlocal_variables \n",
      "torch._export.db.examples.cond_closed_over_variable \n",
      "torch._export.db.examples.cond_operands \n",
      "torch._export.db.examples.cond_predicate \n",
      "torch._export.db.examples.constrain_as_size_example \n",
      "torch._export.db.examples.constrain_as_value_example \n",
      "torch._export.db.examples.decorator \n",
      "torch._export.db.examples.dictionary \n",
      "torch._export.db.examples.dynamic_shape_assert \n",
      "torch._export.db.examples.dynamic_shape_constructor \n",
      "torch._export.db.examples.dynamic_shape_if_guard \n",
      "torch._export.db.examples.dynamic_shape_map \n",
      "torch._export.db.examples.dynamic_shape_round \n",
      "torch._export.db.examples.dynamic_shape_slicing \n",
      "torch._export.db.examples.dynamic_shape_view \n",
      "torch._export.db.examples.fn_with_kwargs \n",
      "torch._export.db.examples.list_contains \n",
      "torch._export.db.examples.list_unpack \n",
      "torch._export.db.examples.model_attr_mutation \n",
      "torch._export.db.examples.nested_function \n",
      "torch._export.db.examples.null_context_manager \n",
      "torch._export.db.examples.optional_input \n",
      "torch._export.db.examples.pytree_flatten \n",
      "torch._export.db.examples.scalar_output \n",
      "torch._export.db.examples.specialized_attribute \n",
      "torch._export.db.examples.static_for_loop \n",
      "torch._export.db.examples.static_if \n",
      "torch._export.db.examples.tensor_setattr \n",
      "torch._export.db.examples.torch_sym_min \n",
      "torch._export.db.examples.type_reflection_method \n",
      "torch._export.db.examples.user_input_mutation \n",
      "torch._export.db.gen_example \n",
      "torch._export.db.logging \n",
      "torch._export.error \n",
      "torch._export.exported_program \n",
      "torch._export.non_strict_utils \n",
      "torch._export.pass_base \n",
      "torch._export.pass_infra \n",
      "torch._export.pass_infra.node_metadata \n",
      "torch._export.pass_infra.proxy_value \n",
      "torch._export.passes \n",
      "torch._export.passes.add_runtime_assertions_for_constraints_pass \n",
      "torch._export.passes.collect_tracepoints_pass \n",
      "torch._export.passes.functionalize_side_effectful_ops_pass \n",
      "torch._export.passes.lift_constants_pass \n",
      "torch._export.passes.remove_runtime_assertions \n",
      "torch._export.passes.replace_set_grad_with_hop_pass \n",
      "torch._export.passes.replace_sym_size_ops_pass \n",
      "torch._export.passes.replace_view_ops_with_view_copy_ops_pass \n",
      "torch._export.serde \n",
      "torch._export.serde.schema \n",
      "torch._export.serde.schema_check \n",
      "torch._export.serde.serialize \n",
      "torch._export.serde.union \n",
      "torch._export.serde.upgrade \n",
      "torch._export.utils \n",
      "torch._export.verifier \n",
      "torch._export.wrappers \n",
      "torch._functorch \n",
      "torch._functorch._aot_autograd \n",
      "torch._functorch._aot_autograd.collect_metadata_analysis - This module is one of the analysis modules - it takes as input a function or graph\n",
      "torch._functorch._aot_autograd.dispatch_and_compile_graph - This module dispatches the graphs to either the forward-only or joint compilation\n",
      "torch._functorch._aot_autograd.functional_utils - This file contains utilities related to functionalization in AOTAutograd:\n",
      "torch._functorch._aot_autograd.input_output_analysis - This module is one of the analysis modules - it takes as input a function or graph\n",
      "torch._functorch._aot_autograd.jit_compile_runtime_wrappers - These are the runtime wrappers that are associated with JIT-compiling.\n",
      "torch._functorch._aot_autograd.logging_utils - Contains utils for logging in AOTAutograd, including managing the names of the graphs under\n",
      "torch._functorch._aot_autograd.runtime_wrappers - This module defines runtime wrappers, which, based on previous analysis attempts to:\n",
      "torch._functorch._aot_autograd.schemas - The various dataclasses, Enums, namedtuples etc used in AOTAutograd. This includes\n",
      "torch._functorch._aot_autograd.subclass_utils - This file contains utilities for tracing through __torch_dispatch__ based tensor subclasses and modes.\n",
      "torch._functorch._aot_autograd.traced_function_transforms - This module is responsible for transforming functions to be traced into a form\n",
      "torch._functorch._aot_autograd.utils - Contains various utils for AOTAutograd, including those for handling collections.\n",
      "torch._functorch.aot_autograd \n",
      "torch._functorch.apis \n",
      "torch._functorch.autograd_function \n",
      "torch._functorch.batch_norm_replacement \n",
      "torch._functorch.benchmark_utils \n",
      "torch._functorch.compile_utils \n",
      "torch._functorch.compilers \n",
      "torch._functorch.config - Global flags for aot autograd\n",
      "torch._functorch.deprecated \n",
      "torch._functorch.eager_transforms \n",
      "torch._functorch.functional_call \n",
      "torch._functorch.fx_minifier \n",
      "torch._functorch.make_functional \n",
      "torch._functorch.partitioners \n",
      "torch._functorch.pyfunctorch \n",
      "torch._functorch.python_key \n",
      "torch._functorch.pytree_hacks \n",
      "torch._functorch.top_operators_github_usage - From https://docs.google.com/spreadsheets/d/12R3nCOLskxPYjjiNkdqy4OdQ65eQp_htebXGODsjSeA/edit#gid=0\n",
      "torch._functorch.utils \n",
      "torch._functorch.vmap \n",
      "torch._guards \n",
      "torch._higher_order_ops \n",
      "torch._higher_order_ops.auto_functionalize \n",
      "torch._higher_order_ops.cond \n",
      "torch._higher_order_ops.effects \n",
      "torch._higher_order_ops.map \n",
      "torch._higher_order_ops.out_dtype \n",
      "torch._higher_order_ops.strict_mode \n",
      "torch._higher_order_ops.torchbind \n",
      "torch._higher_order_ops.triton_kernel_wrap \n",
      "torch._higher_order_ops.utils \n",
      "torch._higher_order_ops.while_loop \n",
      "torch._higher_order_ops.wrap \n",
      "torch._inductor \n",
      "torch._inductor.autotune_process \n",
      "torch._inductor.bounds \n",
      "torch._inductor.codecache \n",
      "torch._inductor.codegen \n",
      "torch._inductor.codegen.common \n",
      "torch._inductor.codegen.cpp \n",
      "torch._inductor.codegen.cpp_wrapper_cpu \n",
      "torch._inductor.codegen.cpp_wrapper_cuda \n",
      "torch._inductor.codegen.cuda \n",
      "torch._inductor.codegen.cuda.cuda_cpp_scheduling \n",
      "torch._inductor.codegen.cuda.cuda_env \n",
      "torch._inductor.codegen.cuda.cuda_kernel \n",
      "torch._inductor.codegen.cuda.cuda_template \n",
      "torch._inductor.codegen.cuda.cutlass_epilogue_gen \n",
      "torch._inductor.codegen.cuda.cutlass_lib_extensions \n",
      "torch._inductor.codegen.cuda.cutlass_lib_extensions.gemm_operation_extensions \n",
      "torch._inductor.codegen.cuda.cutlass_utils \n",
      "torch._inductor.codegen.cuda.device_op_overrides \n",
      "torch._inductor.codegen.cuda.gemm_template \n",
      "torch._inductor.codegen.cuda_combined_scheduling \n",
      "torch._inductor.codegen.memory_planning \n",
      "torch._inductor.codegen.multi_kernel \n",
      "torch._inductor.codegen.triton \n",
      "torch._inductor.codegen.triton_foreach \n",
      "torch._inductor.codegen.triton_split_scan \n",
      "torch._inductor.codegen.triton_utils \n",
      "torch._inductor.codegen.wrapper \n",
      "torch._inductor.comm_analysis \n",
      "torch._inductor.comms \n",
      "torch._inductor.compile_fx \n",
      "torch._inductor.config \n",
      "torch._inductor.constant_folding \n",
      "torch._inductor.coordinate_descent_tuner \n",
      "torch._inductor.cudagraph_trees - CUDA graph trees are a safety abstraction over CUDAGraphs, similar to make_graph_callables,\n",
      "torch._inductor.cudagraph_utils \n",
      "torch._inductor.debug \n",
      "torch._inductor.decomposition \n",
      "torch._inductor.dependencies \n",
      "torch._inductor.exc \n",
      "torch._inductor.freezing \n",
      "torch._inductor.fx_passes \n",
      "torch._inductor.fx_passes.binary_folding \n",
      "torch._inductor.fx_passes.decompose_mem_bound_mm \n",
      "torch._inductor.fx_passes.dedupe_symint_uses \n",
      "torch._inductor.fx_passes.efficient_conv_bn_eval \n",
      "torch._inductor.fx_passes.freezing_patterns \n",
      "torch._inductor.fx_passes.fuse_attention \n",
      "torch._inductor.fx_passes.group_batch_fusion \n",
      "torch._inductor.fx_passes.joint_graph \n",
      "torch._inductor.fx_passes.misc_patterns \n",
      "torch._inductor.fx_passes.mkldnn_fusion \n",
      "torch._inductor.fx_passes.numeric_utils \n",
      "torch._inductor.fx_passes.pad_mm \n",
      "torch._inductor.fx_passes.post_grad \n",
      "torch._inductor.fx_passes.pre_grad \n",
      "torch._inductor.fx_passes.quantization \n",
      "torch._inductor.fx_passes.reinplace \n",
      "torch._inductor.fx_passes.replace_random \n",
      "torch._inductor.fx_passes.serialized_patterns \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_1 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_10 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_11 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_12 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_13 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_14 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_15 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_16 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_17 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_2 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_3 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_4 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_5 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_6 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_7 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_8 \n",
      "torch._inductor.fx_passes.serialized_patterns._sfdp_pattern_9 \n",
      "torch._inductor.fx_passes.serialized_patterns.central_index \n",
      "torch._inductor.fx_passes.split_cat \n",
      "torch._inductor.fx_utils \n",
      "torch._inductor.graph \n",
      "torch._inductor.hooks \n",
      "torch._inductor.index_propagation - This file implements the IndexPropagation ops handler, which wraps an\n",
      "torch._inductor.inductor_prims \n",
      "torch._inductor.ir \n",
      "torch._inductor.kernel \n",
      "torch._inductor.lowering \n",
      "torch._inductor.metrics \n",
      "torch._inductor.ops_handler \n",
      "torch._inductor.optimize_indexing \n",
      "torch._inductor.pattern_matcher \n",
      "torch._inductor.quantized_lowerings \n",
      "torch._inductor.scheduler \n",
      "torch._inductor.select_algorithm \n",
      "torch._inductor.sizevars \n",
      "torch._inductor.test_case \n",
      "torch._inductor.test_operators \n",
      "torch._inductor.triton_helpers \n",
      "torch._inductor.triton_heuristics \n",
      "torch._inductor.utils \n",
      "torch._inductor.virtualized - This file provides a number of \"global\" variables/handlers that are actually\n",
      "torch._inductor.wrapper_benchmark \n",
      "torch._jit_internal - The weak_script annotation needs to be here instead of inside torch/jit/ so it\n",
      "torch._lazy \n",
      "torch._lazy.closure \n",
      "torch._lazy.computation \n",
      "torch._lazy.config \n",
      "torch._lazy.debug \n",
      "torch._lazy.device_context \n",
      "torch._lazy.extract_compiled_graph \n",
      "torch._lazy.ir_cache \n",
      "torch._lazy.metrics \n",
      "torch._lazy.tensor_factory_functions \n",
      "torch._lazy.ts_backend \n",
      "torch._library \n",
      "torch._library.abstract_impl \n",
      "torch._library.simple_registry \n",
      "torch._library.utils \n",
      "torch._linalg_utils - Various linear algebra utility methods for internal use.\n",
      "torch._lobpcg - Locally Optimal Block Preconditioned Conjugate Gradient methods.\n",
      "torch._logging \n",
      "torch._logging._internal \n",
      "torch._logging._registrations \n",
      "torch._logging.structured - Utilities for converting data types into structured JSON for dumping.\n",
      "torch._lowrank - Implement various linear algebra algorithms for low rank matrices.\n",
      "torch._meta_registrations \n",
      "torch._namedtensor_internals \n",
      "torch._numpy \n",
      "torch._numpy._binary_ufuncs_impl - Export torch work functions for binary ufuncs, rename/tweak to match numpy.\n",
      "torch._numpy._casting_dicts \n",
      "torch._numpy._dtypes - Define analogs of numpy dtypes supported by pytorch.\n",
      "torch._numpy._dtypes_impl - Dtypes/scalar type implementaions with torch dtypes.\n",
      "torch._numpy._funcs \n",
      "torch._numpy._funcs_impl - A thin pytorch / numpy compat layer.\n",
      "torch._numpy._getlimits \n",
      "torch._numpy._ndarray \n",
      "torch._numpy._normalizations - \"Normalize\" arguments: convert array_likes to tensors, dtypes to torch dtypes and so on.\n",
      "torch._numpy._reductions_impl - Implementation of reduction operations, to be wrapped into arrays, dtypes etc\n",
      "torch._numpy._ufuncs \n",
      "torch._numpy._unary_ufuncs_impl - Export torch work functions for unary ufuncs, rename/tweak to match numpy.\n",
      "torch._numpy._util - Assorted utilities, which do not need anything other then torch and stdlib.\n",
      "torch._numpy.fft \n",
      "torch._numpy.linalg \n",
      "torch._numpy.random - Wrapper to mimic (parts of) np.random API surface.\n",
      "torch._numpy.testing \n",
      "torch._numpy.testing.utils - Utility function to facilitate testing.\n",
      "torch._ops \n",
      "torch._prims \n",
      "torch._prims.context \n",
      "torch._prims.debug_prims \n",
      "torch._prims.executor \n",
      "torch._prims.rng_prims \n",
      "torch._prims_common \n",
      "torch._prims_common.wrappers \n",
      "torch._python_dispatcher \n",
      "torch._refs \n",
      "torch._refs._conversions \n",
      "torch._refs.fft \n",
      "torch._refs.linalg \n",
      "torch._refs.nn \n",
      "torch._refs.nn.functional \n",
      "torch._refs.special \n",
      "torch._sources \n",
      "torch._storage_docs - Adds docstrings to Storage functions\n",
      "torch._streambase \n",
      "torch._subclasses \n",
      "torch._subclasses.fake_impls \n",
      "torch._subclasses.fake_tensor \n",
      "torch._subclasses.fake_utils \n",
      "torch._subclasses.functional_tensor \n",
      "torch._subclasses.meta_utils \n",
      "torch._subclasses.schema_check_mode \n",
      "torch._tensor \n",
      "torch._tensor_docs - Adds docstrings to Tensor functions\n",
      "torch._tensor_str \n",
      "torch._torch_docs - Adds docstrings to functions defined in the torch._C module.\n",
      "torch._utils \n",
      "torch._utils_internal \n",
      "torch._vendor \n",
      "torch._vendor.packaging \n",
      "torch._vendor.packaging._structures \n",
      "torch._vendor.packaging.version - .. testsetup::\n",
      "torch._vmap_internals \n",
      "torch._weights_only_unpickler \n",
      "torch.amp \n",
      "torch.amp.autocast_mode \n",
      "torch.amp.grad_scaler \n",
      "torch.ao \n",
      "torch.ao.nn \n",
      "torch.ao.nn.intrinsic \n",
      "torch.ao.nn.intrinsic.modules \n",
      "torch.ao.nn.intrinsic.modules.fused \n",
      "torch.ao.nn.intrinsic.qat \n",
      "torch.ao.nn.intrinsic.qat.modules \n",
      "torch.ao.nn.intrinsic.qat.modules.conv_fused \n",
      "torch.ao.nn.intrinsic.qat.modules.linear_fused \n",
      "torch.ao.nn.intrinsic.qat.modules.linear_relu \n",
      "torch.ao.nn.intrinsic.quantized \n",
      "torch.ao.nn.intrinsic.quantized.dynamic \n",
      "torch.ao.nn.intrinsic.quantized.dynamic.modules \n",
      "torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu \n",
      "torch.ao.nn.intrinsic.quantized.modules \n",
      "torch.ao.nn.intrinsic.quantized.modules.bn_relu \n",
      "torch.ao.nn.intrinsic.quantized.modules.conv_add \n",
      "torch.ao.nn.intrinsic.quantized.modules.conv_relu \n",
      "torch.ao.nn.intrinsic.quantized.modules.linear_relu \n",
      "torch.ao.nn.qat \n",
      "torch.ao.nn.qat.dynamic \n",
      "torch.ao.nn.qat.dynamic.modules \n",
      "torch.ao.nn.qat.dynamic.modules.linear \n",
      "torch.ao.nn.qat.modules \n",
      "torch.ao.nn.qat.modules.conv \n",
      "torch.ao.nn.qat.modules.embedding_ops \n",
      "torch.ao.nn.qat.modules.linear \n",
      "torch.ao.nn.quantizable \n",
      "torch.ao.nn.quantizable.modules \n",
      "torch.ao.nn.quantizable.modules.activation \n",
      "torch.ao.nn.quantizable.modules.rnn \n",
      "torch.ao.nn.quantized \n",
      "torch.ao.nn.quantized.dynamic \n",
      "torch.ao.nn.quantized.dynamic.modules \n",
      "torch.ao.nn.quantized.dynamic.modules.conv - Dynamically quantized convolution modules.\n",
      "torch.ao.nn.quantized.dynamic.modules.linear \n",
      "torch.ao.nn.quantized.dynamic.modules.rnn \n",
      "torch.ao.nn.quantized.functional - Functional interface (quantized).\n",
      "torch.ao.nn.quantized.modules \n",
      "torch.ao.nn.quantized.modules.activation \n",
      "torch.ao.nn.quantized.modules.batchnorm \n",
      "torch.ao.nn.quantized.modules.conv - Quantized convolution modules.\n",
      "torch.ao.nn.quantized.modules.dropout \n",
      "torch.ao.nn.quantized.modules.embedding_ops \n",
      "torch.ao.nn.quantized.modules.functional_modules \n",
      "torch.ao.nn.quantized.modules.linear \n",
      "torch.ao.nn.quantized.modules.normalization \n",
      "torch.ao.nn.quantized.modules.rnn \n",
      "torch.ao.nn.quantized.modules.utils \n",
      "torch.ao.nn.quantized.reference \n",
      "torch.ao.nn.quantized.reference.modules \n",
      "torch.ao.nn.quantized.reference.modules.conv \n",
      "torch.ao.nn.quantized.reference.modules.linear \n",
      "torch.ao.nn.quantized.reference.modules.rnn \n",
      "torch.ao.nn.quantized.reference.modules.sparse \n",
      "torch.ao.nn.quantized.reference.modules.utils \n",
      "torch.ao.nn.sparse \n",
      "torch.ao.nn.sparse.quantized \n",
      "torch.ao.nn.sparse.quantized.dynamic \n",
      "torch.ao.nn.sparse.quantized.dynamic.linear \n",
      "torch.ao.nn.sparse.quantized.linear \n",
      "torch.ao.nn.sparse.quantized.utils \n",
      "torch.ao.ns \n",
      "torch.ao.ns._numeric_suite \n",
      "torch.ao.ns._numeric_suite_fx - This module contains tooling to compare weights and activations\n",
      "torch.ao.ns.fx \n",
      "torch.ao.ns.fx.graph_matcher \n",
      "torch.ao.ns.fx.graph_passes \n",
      "torch.ao.ns.fx.mappings \n",
      "torch.ao.ns.fx.n_shadows_utils \n",
      "torch.ao.ns.fx.ns_types \n",
      "torch.ao.ns.fx.pattern_utils \n",
      "torch.ao.ns.fx.qconfig_multi_mapping \n",
      "torch.ao.ns.fx.utils \n",
      "torch.ao.ns.fx.weight_utils \n",
      "torch.ao.pruning \n",
      "torch.ao.pruning._experimental \n",
      "torch.ao.pruning._experimental.activation_sparsifier \n",
      "torch.ao.pruning._experimental.activation_sparsifier.activation_sparsifier \n",
      "torch.ao.pruning._experimental.data_scheduler \n",
      "torch.ao.pruning._experimental.data_scheduler.base_data_scheduler \n",
      "torch.ao.pruning._experimental.data_sparsifier \n",
      "torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier \n",
      "torch.ao.pruning._experimental.data_sparsifier.data_norm_sparsifier \n",
      "torch.ao.pruning._experimental.data_sparsifier.lightning \n",
      "torch.ao.pruning._experimental.data_sparsifier.lightning.callbacks \n",
      "torch.ao.pruning._experimental.data_sparsifier.lightning.callbacks._data_sparstity_utils \n",
      "torch.ao.pruning._experimental.data_sparsifier.lightning.callbacks.data_sparsity \n",
      "torch.ao.pruning._experimental.data_sparsifier.quantization_utils \n",
      "torch.ao.pruning._experimental.pruner \n",
      "torch.ao.pruning._experimental.pruner.FPGM_pruner \n",
      "torch.ao.pruning._experimental.pruner.base_structured_sparsifier \n",
      "torch.ao.pruning._experimental.pruner.lstm_saliency_pruner \n",
      "torch.ao.pruning._experimental.pruner.match_utils - Contains utility functions to check if a pattern is in the graph and return the matching nodes\n",
      "torch.ao.pruning._experimental.pruner.parametrization \n",
      "torch.ao.pruning._experimental.pruner.prune_functions - Collection of conversion functions for linear / conv2d structured pruning\n",
      "torch.ao.pruning._experimental.pruner.saliency_pruner \n",
      "torch.ao.pruning._mappings \n",
      "torch.ao.pruning.scheduler \n",
      "torch.ao.pruning.scheduler.base_scheduler \n",
      "torch.ao.pruning.scheduler.cubic_scheduler \n",
      "torch.ao.pruning.scheduler.lambda_scheduler \n",
      "torch.ao.pruning.sparsifier \n",
      "torch.ao.pruning.sparsifier.base_sparsifier \n",
      "torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier \n",
      "torch.ao.pruning.sparsifier.utils \n",
      "torch.ao.pruning.sparsifier.weight_norm_sparsifier \n",
      "torch.ao.quantization \n",
      "torch.ao.quantization._correct_bias \n",
      "torch.ao.quantization._equalize \n",
      "torch.ao.quantization._learnable_fake_quantize \n",
      "torch.ao.quantization.backend_config \n",
      "torch.ao.quantization.backend_config._common_operator_config_utils \n",
      "torch.ao.quantization.backend_config._qnnpack_pt2e \n",
      "torch.ao.quantization.backend_config.backend_config \n",
      "torch.ao.quantization.backend_config.executorch \n",
      "torch.ao.quantization.backend_config.fbgemm \n",
      "torch.ao.quantization.backend_config.native \n",
      "torch.ao.quantization.backend_config.observation_type \n",
      "torch.ao.quantization.backend_config.onednn \n",
      "torch.ao.quantization.backend_config.qnnpack \n",
      "torch.ao.quantization.backend_config.tensorrt \n",
      "torch.ao.quantization.backend_config.utils \n",
      "torch.ao.quantization.backend_config.x86 \n",
      "torch.ao.quantization.fake_quantize - Implements modules  used to perform fake quantization.\n",
      "torch.ao.quantization.fuse_modules \n",
      "torch.ao.quantization.fuser_method_mappings \n",
      "torch.ao.quantization.fx \n",
      "torch.ao.quantization.fx._decomposed \n",
      "torch.ao.quantization.fx._equalize \n",
      "torch.ao.quantization.fx._lower_to_native_backend \n",
      "torch.ao.quantization.fx._model_report \n",
      "torch.ao.quantization.fx._model_report.detector \n",
      "torch.ao.quantization.fx._model_report.model_report \n",
      "torch.ao.quantization.fx._model_report.model_report_observer \n",
      "torch.ao.quantization.fx._model_report.model_report_visualizer \n",
      "torch.ao.quantization.fx.convert \n",
      "torch.ao.quantization.fx.custom_config \n",
      "torch.ao.quantization.fx.fuse \n",
      "torch.ao.quantization.fx.fuse_handler \n",
      "torch.ao.quantization.fx.graph_module \n",
      "torch.ao.quantization.fx.lower_to_fbgemm \n",
      "torch.ao.quantization.fx.lower_to_qnnpack \n",
      "torch.ao.quantization.fx.lstm_utils \n",
      "torch.ao.quantization.fx.match_utils \n",
      "torch.ao.quantization.fx.pattern_utils \n",
      "torch.ao.quantization.fx.prepare \n",
      "torch.ao.quantization.fx.qconfig_mapping_utils \n",
      "torch.ao.quantization.fx.quantize_handler \n",
      "torch.ao.quantization.fx.tracer \n",
      "torch.ao.quantization.fx.utils \n",
      "torch.ao.quantization.observer - This module implements observers which are used to collect statistics about\n",
      "torch.ao.quantization.pt2e \n",
      "torch.ao.quantization.pt2e.duplicate_dq_pass \n",
      "torch.ao.quantization.pt2e.export_utils \n",
      "torch.ao.quantization.pt2e.generate_numeric_debug_handle \n",
      "torch.ao.quantization.pt2e.graph_utils \n",
      "torch.ao.quantization.pt2e.port_metadata_pass \n",
      "torch.ao.quantization.pt2e.prepare \n",
      "torch.ao.quantization.pt2e.qat_utils \n",
      "torch.ao.quantization.pt2e.representation \n",
      "torch.ao.quantization.pt2e.representation.rewrite \n",
      "torch.ao.quantization.pt2e.utils \n",
      "torch.ao.quantization.qconfig \n",
      "torch.ao.quantization.qconfig_mapping \n",
      "torch.ao.quantization.quant_type \n",
      "torch.ao.quantization.quantization_mappings \n",
      "torch.ao.quantization.quantize \n",
      "torch.ao.quantization.quantize_fx \n",
      "torch.ao.quantization.quantize_jit \n",
      "torch.ao.quantization.quantize_pt2e \n",
      "torch.ao.quantization.quantizer \n",
      "torch.ao.quantization.quantizer.composable_quantizer \n",
      "torch.ao.quantization.quantizer.embedding_quantizer \n",
      "torch.ao.quantization.quantizer.quantizer \n",
      "torch.ao.quantization.quantizer.utils \n",
      "torch.ao.quantization.quantizer.x86_inductor_quantizer \n",
      "torch.ao.quantization.quantizer.xnnpack_quantizer \n",
      "torch.ao.quantization.quantizer.xnnpack_quantizer_utils \n",
      "torch.ao.quantization.stubs \n",
      "torch.ao.quantization.utils - Utils shared by different modes of quantization (eager/graph)\n",
      "torch.autograd - ``torch.autograd`` provides classes and functions implementing automatic\n",
      "torch.autograd._functions \n",
      "torch.autograd._functions.tensor \n",
      "torch.autograd._functions.utils \n",
      "torch.autograd.anomaly_mode \n",
      "torch.autograd.forward_ad \n",
      "torch.autograd.function \n",
      "torch.autograd.functional \n",
      "torch.autograd.grad_mode \n",
      "torch.autograd.gradcheck \n",
      "torch.autograd.graph \n",
      "torch.autograd.profiler \n",
      "torch.autograd.profiler_legacy \n",
      "torch.autograd.profiler_util \n",
      "torch.autograd.variable \n",
      "torch.backends \n",
      "torch.backends._coreml \n",
      "torch.backends._coreml.preprocess \n",
      "torch.backends._nnapi \n",
      "torch.backends._nnapi.prepare \n",
      "torch.backends._nnapi.serializer \n",
      "torch.backends.cpu \n",
      "torch.backends.cuda \n",
      "torch.backends.cudnn \n",
      "torch.backends.cudnn.rnn \n",
      "torch.backends.mha \n",
      "torch.backends.mkl \n",
      "torch.backends.mkldnn \n",
      "torch.backends.mps \n",
      "torch.backends.nnpack \n",
      "torch.backends.openmp \n",
      "torch.backends.opt_einsum \n",
      "torch.backends.quantized \n",
      "torch.backends.xeon \n",
      "torch.backends.xeon.run_cpu - This is a script for launching PyTorch inference on Intel(R) Xeon(R) Scalable Processors with optimal configurations.\n",
      "torch.backends.xnnpack \n",
      "torch.compiler \n",
      "torch.contrib \n",
      "torch.contrib._tensorboard_vis \n",
      "torch.cpu - This package implements abstractions found in ``torch.cuda``\n",
      "torch.cpu.amp \n",
      "torch.cpu.amp.autocast_mode \n",
      "torch.cpu.amp.grad_scaler \n",
      "torch.cuda - This package adds support for CUDA tensor types.\n",
      "torch.cuda._memory_viz \n",
      "torch.cuda._sanitizer - This module introduces CUDA Sanitizer, a tool for detecting synchronization errors between kernels ran on different streams.\n",
      "torch.cuda._utils \n",
      "torch.cuda.amp \n",
      "torch.cuda.amp.autocast_mode \n",
      "torch.cuda.amp.common \n",
      "torch.cuda.amp.grad_scaler \n",
      "torch.cuda.comm \n",
      "torch.cuda.error \n",
      "torch.cuda.graphs \n",
      "torch.cuda.jiterator \n",
      "torch.cuda.memory - This package adds support for device memory management implemented in CUDA.\n",
      "torch.cuda.nccl \n",
      "torch.cuda.nvtx - This package adds support for NVIDIA Tools Extension (NVTX) used in profiling.\n",
      "torch.cuda.profiler \n",
      "torch.cuda.random \n",
      "torch.cuda.sparse \n",
      "torch.cuda.streams \n",
      "torch.distributed \n",
      "torch.distributed._composable \n",
      "torch.distributed._composable.checkpoint_activation \n",
      "torch.distributed._composable.contract \n",
      "torch.distributed._composable.fsdp \n",
      "torch.distributed._composable.fsdp._fsdp_api \n",
      "torch.distributed._composable.fsdp._fsdp_collectives \n",
      "torch.distributed._composable.fsdp._fsdp_common \n",
      "torch.distributed._composable.fsdp._fsdp_init \n",
      "torch.distributed._composable.fsdp._fsdp_param \n",
      "torch.distributed._composable.fsdp._fsdp_param_group \n",
      "torch.distributed._composable.fsdp._fsdp_state \n",
      "torch.distributed._composable.fsdp.fully_shard \n",
      "torch.distributed._composable.fully_shard \n",
      "torch.distributed._composable.replicate \n",
      "torch.distributed._composable_state \n",
      "torch.distributed._functional_collectives \n",
      "torch.distributed._functional_collectives_impl \n",
      "torch.distributed._shard \n",
      "torch.distributed._shard._utils \n",
      "torch.distributed._shard.api \n",
      "torch.distributed._shard.checkpoint \n",
      "torch.distributed._shard.checkpoint._dedup_save_plans \n",
      "torch.distributed._shard.checkpoint._dedup_tensors \n",
      "torch.distributed._shard.checkpoint._fsspec_filesystem \n",
      "torch.distributed._shard.checkpoint._nested_dict \n",
      "torch.distributed._shard.checkpoint._sharded_tensor_utils \n",
      "torch.distributed._shard.checkpoint._storage_utils \n",
      "torch.distributed._shard.checkpoint._traverse \n",
      "torch.distributed._shard.checkpoint.api \n",
      "torch.distributed._shard.checkpoint.default_planner \n",
      "torch.distributed._shard.checkpoint.filesystem \n",
      "torch.distributed._shard.checkpoint.format_utils \n",
      "torch.distributed._shard.checkpoint.fsspec \n",
      "torch.distributed._shard.checkpoint.metadata \n",
      "torch.distributed._shard.checkpoint.optimizer \n",
      "torch.distributed._shard.checkpoint.planner \n",
      "torch.distributed._shard.checkpoint.planner_helpers \n",
      "torch.distributed._shard.checkpoint.resharding \n",
      "torch.distributed._shard.checkpoint.state_dict \n",
      "torch.distributed._shard.checkpoint.state_dict_loader \n",
      "torch.distributed._shard.checkpoint.state_dict_saver \n",
      "torch.distributed._shard.checkpoint.stateful \n",
      "torch.distributed._shard.checkpoint.storage \n",
      "torch.distributed._shard.checkpoint.utils \n",
      "torch.distributed._shard.common_op_utils \n",
      "torch.distributed._shard.metadata \n",
      "torch.distributed._shard.op_registry_utils \n",
      "torch.distributed._shard.sharded_optim \n",
      "torch.distributed._shard.sharded_optim.api \n",
      "torch.distributed._shard.sharded_tensor \n",
      "torch.distributed._shard.sharded_tensor._ops \n",
      "torch.distributed._shard.sharded_tensor._ops._common \n",
      "torch.distributed._shard.sharded_tensor._ops.binary_cmp \n",
      "torch.distributed._shard.sharded_tensor._ops.init \n",
      "torch.distributed._shard.sharded_tensor._ops.misc_ops \n",
      "torch.distributed._shard.sharded_tensor._ops.tensor_ops \n",
      "torch.distributed._shard.sharded_tensor.api \n",
      "torch.distributed._shard.sharded_tensor.logger \n",
      "torch.distributed._shard.sharded_tensor.logging_handlers \n",
      "torch.distributed._shard.sharded_tensor.metadata \n",
      "torch.distributed._shard.sharded_tensor.reshard \n",
      "torch.distributed._shard.sharded_tensor.shard \n",
      "torch.distributed._shard.sharded_tensor.utils \n",
      "torch.distributed._shard.sharder \n",
      "torch.distributed._shard.sharding_plan \n",
      "torch.distributed._shard.sharding_plan.api \n",
      "torch.distributed._shard.sharding_spec \n",
      "torch.distributed._shard.sharding_spec._internals \n",
      "torch.distributed._shard.sharding_spec.api \n",
      "torch.distributed._shard.sharding_spec.chunk_sharding_spec \n",
      "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops \n",
      "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops._common \n",
      "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.embedding \n",
      "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.embedding_bag \n",
      "torch.distributed._sharded_tensor \n",
      "torch.distributed._sharded_tensor._ops \n",
      "torch.distributed._sharded_tensor._ops._common \n",
      "torch.distributed._sharded_tensor._ops.binary_cmp \n",
      "torch.distributed._sharded_tensor._ops.init \n",
      "torch.distributed._sharded_tensor._ops.misc_ops \n",
      "torch.distributed._sharded_tensor._ops.tensor_ops \n",
      "torch.distributed._sharded_tensor.api \n",
      "torch.distributed._sharded_tensor.logger \n",
      "torch.distributed._sharded_tensor.logging_handlers \n",
      "torch.distributed._sharded_tensor.metadata \n",
      "torch.distributed._sharded_tensor.reshard \n",
      "torch.distributed._sharded_tensor.shard \n",
      "torch.distributed._sharded_tensor.utils \n",
      "torch.distributed._sharding_spec \n",
      "torch.distributed._sharding_spec._internals \n",
      "torch.distributed._sharding_spec.api \n",
      "torch.distributed._sharding_spec.chunk_sharding_spec \n",
      "torch.distributed._sharding_spec.chunk_sharding_spec_ops \n",
      "torch.distributed._sharding_spec.chunk_sharding_spec_ops._common \n",
      "torch.distributed._sharding_spec.chunk_sharding_spec_ops.embedding \n",
      "torch.distributed._sharding_spec.chunk_sharding_spec_ops.embedding_bag \n",
      "torch.distributed._spmd \n",
      "torch.distributed._spmd.api \n",
      "torch.distributed._spmd.batch_dim_utils \n",
      "torch.distributed._spmd.comm_tensor \n",
      "torch.distributed._spmd.config \n",
      "torch.distributed._spmd.data_parallel \n",
      "torch.distributed._spmd.distribute \n",
      "torch.distributed._spmd.experimental_ops \n",
      "torch.distributed._spmd.gm_transformation \n",
      "torch.distributed._spmd.graph_optimization \n",
      "torch.distributed._spmd.graph_utils \n",
      "torch.distributed._spmd.iter_graph_module \n",
      "torch.distributed._spmd.log_utils \n",
      "torch.distributed._spmd.parallel_mode \n",
      "torch.distributed._spmd.partial_lower \n",
      "torch.distributed._state_dict_utils \n",
      "torch.distributed._tensor \n",
      "torch.distributed._tensor._collective_utils \n",
      "torch.distributed._tensor._utils \n",
      "torch.distributed._tensor.api \n",
      "torch.distributed._tensor.debug \n",
      "torch.distributed._tensor.debug.comm_mode \n",
      "torch.distributed._tensor.debug.op_coverage \n",
      "torch.distributed._tensor.debug.visualize_sharding \n",
      "torch.distributed._tensor.device_mesh \n",
      "torch.distributed._tensor.dispatch \n",
      "torch.distributed._tensor.experimental \n",
      "torch.distributed._tensor.experimental.tp_transform \n",
      "torch.distributed._tensor.op_schema \n",
      "torch.distributed._tensor.ops \n",
      "torch.distributed._tensor.ops.basic_strategy \n",
      "torch.distributed._tensor.ops.common_rules \n",
      "torch.distributed._tensor.ops.conv_ops \n",
      "torch.distributed._tensor.ops.embedding_ops \n",
      "torch.distributed._tensor.ops.experimental_ops \n",
      "torch.distributed._tensor.ops.math_ops \n",
      "torch.distributed._tensor.ops.matrix_ops \n",
      "torch.distributed._tensor.ops.pointwise_ops \n",
      "torch.distributed._tensor.ops.random_ops \n",
      "torch.distributed._tensor.ops.tensor_ops \n",
      "torch.distributed._tensor.ops.utils \n",
      "torch.distributed._tensor.ops.view_ops \n",
      "torch.distributed._tensor.placement_types \n",
      "torch.distributed._tensor.random \n",
      "torch.distributed._tensor.redistribute \n",
      "torch.distributed._tensor.sharding_prop \n",
      "torch.distributed._tensor.tp_conv \n",
      "torch.distributed._tools \n",
      "torch.distributed._tools.memory_tracker \n",
      "torch.distributed.algorithms \n",
      "torch.distributed.algorithms._checkpoint \n",
      "torch.distributed.algorithms._checkpoint.checkpoint_wrapper \n",
      "torch.distributed.algorithms._comm_hooks \n",
      "torch.distributed.algorithms._comm_hooks.default_hooks \n",
      "torch.distributed.algorithms._optimizer_overlap \n",
      "torch.distributed.algorithms._optimizer_overlap.optimizer_overlap \n",
      "torch.distributed.algorithms._quantization \n",
      "torch.distributed.algorithms._quantization.quantization \n",
      "torch.distributed.algorithms.ddp_comm_hooks \n",
      "torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook \n",
      "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks \n",
      "torch.distributed.algorithms.ddp_comm_hooks.default_hooks \n",
      "torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks \n",
      "torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks \n",
      "torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook \n",
      "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook \n",
      "torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks \n",
      "torch.distributed.algorithms.join \n",
      "torch.distributed.algorithms.model_averaging \n",
      "torch.distributed.algorithms.model_averaging.averagers \n",
      "torch.distributed.algorithms.model_averaging.hierarchical_model_averager \n",
      "torch.distributed.algorithms.model_averaging.utils \n",
      "torch.distributed.argparse_util \n",
      "torch.distributed.autograd \n",
      "torch.distributed.c10d_logger \n",
      "torch.distributed.checkpoint \n",
      "torch.distributed.checkpoint._dedup_save_plans \n",
      "torch.distributed.checkpoint._dedup_tensors \n",
      "torch.distributed.checkpoint._fsspec_filesystem \n",
      "torch.distributed.checkpoint._nested_dict \n",
      "torch.distributed.checkpoint._sharded_tensor_utils \n",
      "torch.distributed.checkpoint._storage_utils \n",
      "torch.distributed.checkpoint._traverse \n",
      "torch.distributed.checkpoint.api \n",
      "torch.distributed.checkpoint.default_planner \n",
      "torch.distributed.checkpoint.filesystem \n",
      "torch.distributed.checkpoint.format_utils \n",
      "torch.distributed.checkpoint.fsspec \n",
      "torch.distributed.checkpoint.metadata \n",
      "torch.distributed.checkpoint.optimizer \n",
      "torch.distributed.checkpoint.planner \n",
      "torch.distributed.checkpoint.planner_helpers \n",
      "torch.distributed.checkpoint.resharding \n",
      "torch.distributed.checkpoint.state_dict \n",
      "torch.distributed.checkpoint.state_dict_loader \n",
      "torch.distributed.checkpoint.state_dict_saver \n",
      "torch.distributed.checkpoint.stateful \n",
      "torch.distributed.checkpoint.storage \n",
      "torch.distributed.checkpoint.utils \n",
      "torch.distributed.collective_utils - A set of primitive functions for performing collective ops.\n",
      "torch.distributed.constants \n",
      "torch.distributed.device_mesh \n",
      "torch.distributed.distributed_c10d - Distributed Collective Communication (c10d).\n",
      "torch.distributed.elastic - Torchelastic agent and user worker failover contract:\n",
      "torch.distributed.elastic.agent \n",
      "torch.distributed.elastic.agent.server - The elastic agent is the control plane of torchelastic.\n",
      "torch.distributed.elastic.agent.server.api \n",
      "torch.distributed.elastic.agent.server.local_elastic_agent \n",
      "torch.distributed.elastic.events - Module contains events processing mechanisms that are integrated with the standard python logging.\n",
      "torch.distributed.elastic.events.api \n",
      "torch.distributed.elastic.events.handlers \n",
      "torch.distributed.elastic.metrics - Metrics API.\n",
      "torch.distributed.elastic.metrics.api \n",
      "torch.distributed.elastic.multiprocessing - Library that launches and manages ``n`` copies of worker subprocesses either specified by a function or a binary.\n",
      "torch.distributed.elastic.multiprocessing.api \n",
      "torch.distributed.elastic.multiprocessing.errors - Each host in a distributed PyTorch job runs with a single TorchElastic agent,\n",
      "torch.distributed.elastic.multiprocessing.errors.error_handler \n",
      "torch.distributed.elastic.multiprocessing.errors.handlers \n",
      "torch.distributed.elastic.multiprocessing.redirects \n",
      "torch.distributed.elastic.multiprocessing.subprocess_handler \n",
      "torch.distributed.elastic.multiprocessing.subprocess_handler.handlers \n",
      "torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler \n",
      "torch.distributed.elastic.multiprocessing.tail_log \n",
      "torch.distributed.elastic.rendezvous - In the context of Torch Distributed Elastic we use the term *rendezvous* to\n",
      "torch.distributed.elastic.rendezvous.api \n",
      "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend \n",
      "torch.distributed.elastic.rendezvous.dynamic_rendezvous \n",
      "torch.distributed.elastic.rendezvous.etcd_rendezvous \n",
      "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend \n",
      "torch.distributed.elastic.rendezvous.etcd_server \n",
      "torch.distributed.elastic.rendezvous.etcd_store \n",
      "torch.distributed.elastic.rendezvous.registry \n",
      "torch.distributed.elastic.rendezvous.static_tcp_rendezvous \n",
      "torch.distributed.elastic.rendezvous.utils \n",
      "torch.distributed.elastic.timer - Expiration timers are set up on the same process as the agent and\n",
      "torch.distributed.elastic.timer.api \n",
      "torch.distributed.elastic.timer.file_based_local_timer \n",
      "torch.distributed.elastic.timer.local_timer \n",
      "torch.distributed.elastic.utils \n",
      "torch.distributed.elastic.utils.api \n",
      "torch.distributed.elastic.utils.data \n",
      "torch.distributed.elastic.utils.data.cycling_iterator \n",
      "torch.distributed.elastic.utils.data.elastic_distributed_sampler \n",
      "torch.distributed.elastic.utils.distributed \n",
      "torch.distributed.elastic.utils.log_level \n",
      "torch.distributed.elastic.utils.logging \n",
      "torch.distributed.elastic.utils.store \n",
      "torch.distributed.fsdp \n",
      "torch.distributed.fsdp._common_utils - This file includes private common utilities for FSDP.\n",
      "torch.distributed.fsdp._debug_utils \n",
      "torch.distributed.fsdp._dynamo_utils \n",
      "torch.distributed.fsdp._exec_order_utils \n",
      "torch.distributed.fsdp._flat_param \n",
      "torch.distributed.fsdp._fsdp_extensions \n",
      "torch.distributed.fsdp._init_utils \n",
      "torch.distributed.fsdp._limiter_utils \n",
      "torch.distributed.fsdp._optim_utils \n",
      "torch.distributed.fsdp._runtime_utils \n",
      "torch.distributed.fsdp._shard_utils \n",
      "torch.distributed.fsdp._state_dict_utils \n",
      "torch.distributed.fsdp._trace_utils \n",
      "torch.distributed.fsdp._traversal_utils - NOTE: This file must be imported like\n",
      "torch.distributed.fsdp._unshard_param_utils \n",
      "torch.distributed.fsdp._wrap_utils \n",
      "torch.distributed.fsdp.api - This file includes public APIs for FSDP such as the classes used for the\n",
      "torch.distributed.fsdp.fully_sharded_data_parallel \n",
      "torch.distributed.fsdp.sharded_grad_scaler \n",
      "torch.distributed.fsdp.wrap \n",
      "torch.distributed.launch - Module ``torch.distributed.launch``.\n",
      "torch.distributed.launcher \n",
      "torch.distributed.launcher.api \n",
      "torch.distributed.logging_handlers \n",
      "torch.distributed.nn \n",
      "torch.distributed.nn.api \n",
      "torch.distributed.nn.api.remote_module \n",
      "torch.distributed.nn.functional \n",
      "torch.distributed.nn.jit \n",
      "torch.distributed.nn.jit.instantiator \n",
      "torch.distributed.nn.jit.templates \n",
      "torch.distributed.nn.jit.templates.remote_module_template \n",
      "torch.distributed.optim - :mod:`torch.distributed.optim` exposes DistributedOptimizer, which takes a list\n",
      "torch.distributed.optim.apply_optimizer_in_backward \n",
      "torch.distributed.optim.functional_adadelta \n",
      "torch.distributed.optim.functional_adagrad \n",
      "torch.distributed.optim.functional_adam \n",
      "torch.distributed.optim.functional_adamax \n",
      "torch.distributed.optim.functional_adamw \n",
      "torch.distributed.optim.functional_rmsprop \n",
      "torch.distributed.optim.functional_rprop \n",
      "torch.distributed.optim.functional_sgd \n",
      "torch.distributed.optim.named_optimizer \n",
      "torch.distributed.optim.optimizer \n",
      "torch.distributed.optim.post_localSGD_optimizer \n",
      "torch.distributed.optim.utils \n",
      "torch.distributed.optim.zero_redundancy_optimizer - Zero Redundancy Optimizer.\n",
      "torch.distributed.pipeline \n",
      "torch.distributed.pipeline.sync - A Pipe implementation in PyTorch.\n",
      "torch.distributed.pipeline.sync._balance - A helper to roughly balance a sequential module.\n",
      "torch.distributed.pipeline.sync._balance.blockpartition - Implements \"Block Partitions of Sequences\" by Imre Bárány et al.\n",
      "torch.distributed.pipeline.sync._balance.profile - Per-layer profilers.\n",
      "torch.distributed.pipeline.sync.batchnorm - Tracks the running statistics per mini-batch instead of micro-batch.\n",
      "torch.distributed.pipeline.sync.checkpoint - Checkpointing with preceding recomputation.\n",
      "torch.distributed.pipeline.sync.copy - Autograd functions for stream-aware CUDA copy.\n",
      "torch.distributed.pipeline.sync.dependency - Arbitrary dependency between two autograd lanes.\n",
      "torch.distributed.pipeline.sync.microbatch - Manipulation of micro-batches.\n",
      "torch.distributed.pipeline.sync.phony - Provides phony for arbitrary dependency in a autograd graph.\n",
      "torch.distributed.pipeline.sync.pipe - The Pipe interface.\n",
      "torch.distributed.pipeline.sync.pipeline - The pipeline parallelism of Pipe.\n",
      "torch.distributed.pipeline.sync.skip - Supports efficiency with skip connections.\n",
      "torch.distributed.pipeline.sync.skip.layout - Static skip connection layout of ``@skippable`` modules.\n",
      "torch.distributed.pipeline.sync.skip.namespace - Provides isolated namespace of skip tensors.\n",
      "torch.distributed.pipeline.sync.skip.portal - Portal keeps a tensor in the pocket plane. The tensor becomes hidden to the\n",
      "torch.distributed.pipeline.sync.skip.skippable - The user interface to define skip connections.\n",
      "torch.distributed.pipeline.sync.skip.tracker - Tracks skip tensors on a thread.\n",
      "torch.distributed.pipeline.sync.stream - Utilities for eliminating boilerplate code to handle abstract streams with\n",
      "torch.distributed.pipeline.sync.utils \n",
      "torch.distributed.pipeline.sync.worker - Multithreading in pipeline parallelism.\n",
      "torch.distributed.remote_device \n",
      "torch.distributed.rendezvous \n",
      "torch.distributed.rpc \n",
      "torch.distributed.rpc._testing \n",
      "torch.distributed.rpc._testing.faulty_agent_backend_registry \n",
      "torch.distributed.rpc._utils \n",
      "torch.distributed.rpc.api \n",
      "torch.distributed.rpc.backend_registry \n",
      "torch.distributed.rpc.constants \n",
      "torch.distributed.rpc.functions \n",
      "torch.distributed.rpc.internal \n",
      "torch.distributed.rpc.options \n",
      "torch.distributed.rpc.rref_proxy \n",
      "torch.distributed.rpc.server_process_global_profiler \n",
      "torch.distributed.run - Superset of ``torch.distributed.launch``.\n",
      "torch.distributed.tensor \n",
      "torch.distributed.tensor.parallel \n",
      "torch.distributed.tensor.parallel._data_parallel_utils \n",
      "torch.distributed.tensor.parallel._utils \n",
      "torch.distributed.tensor.parallel.api \n",
      "torch.distributed.tensor.parallel.ddp \n",
      "torch.distributed.tensor.parallel.fsdp \n",
      "torch.distributed.tensor.parallel.input_reshard \n",
      "torch.distributed.tensor.parallel.loss \n",
      "torch.distributed.tensor.parallel.style \n",
      "torch.distributed.utils \n",
      "torch.distributions - The ``distributions`` package contains parameterizable probability distributions\n",
      "torch.distributions.bernoulli \n",
      "torch.distributions.beta \n",
      "torch.distributions.binomial \n",
      "torch.distributions.categorical \n",
      "torch.distributions.cauchy \n",
      "torch.distributions.chi2 \n",
      "torch.distributions.constraint_registry - PyTorch provides two global :class:`ConstraintRegistry` objects that link\n",
      "torch.distributions.constraints - The following constraints are implemented:\n",
      "torch.distributions.continuous_bernoulli \n",
      "torch.distributions.dirichlet \n",
      "torch.distributions.distribution \n",
      "torch.distributions.exp_family \n",
      "torch.distributions.exponential \n",
      "torch.distributions.fishersnedecor \n",
      "torch.distributions.gamma \n",
      "torch.distributions.geometric \n",
      "torch.distributions.gumbel \n",
      "torch.distributions.half_cauchy \n",
      "torch.distributions.half_normal \n",
      "torch.distributions.independent \n",
      "torch.distributions.inverse_gamma \n",
      "torch.distributions.kl \n",
      "torch.distributions.kumaraswamy \n",
      "torch.distributions.laplace \n",
      "torch.distributions.lkj_cholesky - This closely follows the implementation in NumPyro (https://github.com/pyro-ppl/numpyro).\n",
      "torch.distributions.log_normal \n",
      "torch.distributions.logistic_normal \n",
      "torch.distributions.lowrank_multivariate_normal \n",
      "torch.distributions.mixture_same_family \n",
      "torch.distributions.multinomial \n",
      "torch.distributions.multivariate_normal \n",
      "torch.distributions.negative_binomial \n",
      "torch.distributions.normal \n",
      "torch.distributions.one_hot_categorical \n",
      "torch.distributions.pareto \n",
      "torch.distributions.poisson \n",
      "torch.distributions.relaxed_bernoulli \n",
      "torch.distributions.relaxed_categorical \n",
      "torch.distributions.studentT \n",
      "torch.distributions.transformed_distribution \n",
      "torch.distributions.transforms \n",
      "torch.distributions.uniform \n",
      "torch.distributions.utils \n",
      "torch.distributions.von_mises \n",
      "torch.distributions.weibull \n",
      "torch.distributions.wishart \n",
      "torch.export \n",
      "torch.export._remove_auto_functionalized_pass \n",
      "torch.export._remove_effect_tokens_pass \n",
      "torch.export._safeguard \n",
      "torch.export._trace \n",
      "torch.export._tree_utils \n",
      "torch.export._unlift \n",
      "torch.export.custom_obj \n",
      "torch.export.dynamic_shapes \n",
      "torch.export.exported_program \n",
      "torch.export.graph_signature \n",
      "torch.export.unflatten \n",
      "torch.fft \n",
      "torch.func \n",
      "torch.functional \n",
      "torch.futures \n",
      "torch.fx \n",
      "torch.fx._compatibility \n",
      "torch.fx._lazy_graph_module \n",
      "torch.fx._pytree \n",
      "torch.fx._symbolic_trace \n",
      "torch.fx.annotate \n",
      "torch.fx.config \n",
      "torch.fx.experimental \n",
      "torch.fx.experimental._backward_state \n",
      "torch.fx.experimental._config \n",
      "torch.fx.experimental._sym_dispatch_mode \n",
      "torch.fx.experimental.accelerator_partitioner \n",
      "torch.fx.experimental.const_fold \n",
      "torch.fx.experimental.debug \n",
      "torch.fx.experimental.graph_gradual_typechecker \n",
      "torch.fx.experimental.merge_matmul \n",
      "torch.fx.experimental.meta_tracer \n",
      "torch.fx.experimental.migrate_gradual_types \n",
      "torch.fx.experimental.migrate_gradual_types.constraint \n",
      "torch.fx.experimental.migrate_gradual_types.constraint_generator \n",
      "torch.fx.experimental.migrate_gradual_types.constraint_transformation \n",
      "torch.fx.experimental.migrate_gradual_types.operation \n",
      "torch.fx.experimental.migrate_gradual_types.transform_to_z3 \n",
      "torch.fx.experimental.migrate_gradual_types.util \n",
      "torch.fx.experimental.migrate_gradual_types.z3_types \n",
      "torch.fx.experimental.normalize \n",
      "torch.fx.experimental.optimization \n",
      "torch.fx.experimental.partitioner_utils \n",
      "torch.fx.experimental.proxy_tensor \n",
      "torch.fx.experimental.recording \n",
      "torch.fx.experimental.refinement_types \n",
      "torch.fx.experimental.rewriter \n",
      "torch.fx.experimental.schema_type_annotation \n",
      "torch.fx.experimental.sym_node - This file does three things:\n",
      "torch.fx.experimental.symbolic_shapes - ``torch.fx.experimental.symbolic_shapes`` provides interfaces for interacting with\n",
      "torch.fx.experimental.unification \n",
      "torch.fx.experimental.unification.core \n",
      "torch.fx.experimental.unification.dispatch \n",
      "torch.fx.experimental.unification.match \n",
      "torch.fx.experimental.unification.more \n",
      "torch.fx.experimental.unification.multipledispatch \n",
      "torch.fx.experimental.unification.multipledispatch.conflict \n",
      "torch.fx.experimental.unification.multipledispatch.core \n",
      "torch.fx.experimental.unification.multipledispatch.dispatcher \n",
      "torch.fx.experimental.unification.multipledispatch.utils \n",
      "torch.fx.experimental.unification.multipledispatch.variadic \n",
      "torch.fx.experimental.unification.unification_tools \n",
      "torch.fx.experimental.unification.utils \n",
      "torch.fx.experimental.unification.variable \n",
      "torch.fx.experimental.unify_refinements \n",
      "torch.fx.experimental.validator \n",
      "torch.fx.graph \n",
      "torch.fx.graph_module \n",
      "torch.fx.immutable_collections \n",
      "torch.fx.interpreter \n",
      "torch.fx.node \n",
      "torch.fx.operator_schemas \n",
      "torch.fx.passes \n",
      "torch.fx.passes.annotate_getitem_nodes \n",
      "torch.fx.passes.backends \n",
      "torch.fx.passes.backends.cudagraphs \n",
      "torch.fx.passes.dialect \n",
      "torch.fx.passes.dialect.common \n",
      "torch.fx.passes.dialect.common.cse_pass \n",
      "torch.fx.passes.fake_tensor_prop \n",
      "torch.fx.passes.graph_drawer \n",
      "torch.fx.passes.graph_manipulation \n",
      "torch.fx.passes.infra \n",
      "torch.fx.passes.infra.partitioner \n",
      "torch.fx.passes.infra.pass_base \n",
      "torch.fx.passes.infra.pass_manager \n",
      "torch.fx.passes.net_min_base \n",
      "torch.fx.passes.operator_support \n",
      "torch.fx.passes.param_fetch \n",
      "torch.fx.passes.pass_manager \n",
      "torch.fx.passes.reinplace \n",
      "torch.fx.passes.shape_prop \n",
      "torch.fx.passes.split_module \n",
      "torch.fx.passes.split_utils \n",
      "torch.fx.passes.splitter_base \n",
      "torch.fx.passes.tests \n",
      "torch.fx.passes.tests.test_pass_manager \n",
      "torch.fx.passes.tools_common \n",
      "torch.fx.passes.utils \n",
      "torch.fx.passes.utils.common \n",
      "torch.fx.passes.utils.fuser_utils \n",
      "torch.fx.passes.utils.matcher_utils \n",
      "torch.fx.passes.utils.matcher_with_name_node_map_utils \n",
      "torch.fx.passes.utils.source_matcher_utils \n",
      "torch.fx.proxy \n",
      "torch.fx.subgraph_rewriter \n",
      "torch.fx.tensor_type \n",
      "torch.fx.traceback \n",
      "torch.hub \n",
      "torch.jit \n",
      "torch.jit._async - Async API.\n",
      "torch.jit._await \n",
      "torch.jit._builtins \n",
      "torch.jit._check \n",
      "torch.jit._dataclass_impls \n",
      "torch.jit._decomposition_utils \n",
      "torch.jit._decompositions \n",
      "torch.jit._freeze - Freezing.\n",
      "torch.jit._fuser \n",
      "torch.jit._ir_utils \n",
      "torch.jit._logging \n",
      "torch.jit._monkeytype_config \n",
      "torch.jit._passes \n",
      "torch.jit._passes._property_propagation - Tools to help with tensor property propagation.\n",
      "torch.jit._pickle \n",
      "torch.jit._recursive \n",
      "torch.jit._script - TorchScript.\n",
      "torch.jit._serialization - Serialization.\n",
      "torch.jit._shape_functions \n",
      "torch.jit._state - JIT-related state.\n",
      "torch.jit._trace - Tracing.\n",
      "torch.jit.annotations \n",
      "torch.jit.frontend \n",
      "torch.jit.generate_bytecode \n",
      "torch.jit.mobile \n",
      "torch.jit.quantized \n",
      "torch.jit.supported_ops \n",
      "torch.jit.unsupported_tensor_ops \n",
      "torch.library \n",
      "torch.linalg \n",
      "torch.masked \n",
      "torch.masked._docs \n",
      "torch.masked._ops \n",
      "torch.masked.maskedtensor \n",
      "torch.masked.maskedtensor._ops_refs \n",
      "torch.masked.maskedtensor.binary \n",
      "torch.masked.maskedtensor.core \n",
      "torch.masked.maskedtensor.creation \n",
      "torch.masked.maskedtensor.passthrough - These are functions that should simply be applied to both mask and data.\n",
      "torch.masked.maskedtensor.reductions \n",
      "torch.masked.maskedtensor.unary \n",
      "torch.monitor \n",
      "torch.mps - This package enables an interface for accessing MPS (Metal Performance Shaders) backend in Python.\n",
      "torch.mps.event \n",
      "torch.mps.profiler \n",
      "torch.multiprocessing - torch.multiprocessing is a wrapper around the native :mod:`multiprocessing` module.\n",
      "torch.multiprocessing._atfork \n",
      "torch.multiprocessing.pool \n",
      "torch.multiprocessing.queue \n",
      "torch.multiprocessing.reductions \n",
      "torch.multiprocessing.spawn \n",
      "torch.nested \n",
      "torch.nested._internal \n",
      "torch.nested._internal.nested_tensor \n",
      "torch.nested._internal.ops \n",
      "torch.nested._internal.sdpa \n",
      "torch.nn \n",
      "torch.nn._reduction \n",
      "torch.nn.attention - This module contains functions and classes that alter the behavior of torch.nn.functional.scaled_dot_product_attention\n",
      "torch.nn.attention._utils - Defines utilities for interacting with scaled_dot_product_attention\n",
      "torch.nn.attention.bias - Defines bias subclasses that work with scaled_dot_product_attention\n",
      "torch.nn.backends \n",
      "torch.nn.backends.thnn \n",
      "torch.nn.common_types \n",
      "torch.nn.cpp - Functionality for Python <-> C++ frontend inter-op.\n",
      "torch.nn.functional - Functional interface.\n",
      "torch.nn.grad - Gradient interface.\n",
      "torch.nn.init - This file contains utilities for initializing neural network parameters.\n",
      "torch.nn.intrinsic \n",
      "torch.nn.intrinsic.modules \n",
      "torch.nn.intrinsic.modules.fused \n",
      "torch.nn.intrinsic.qat \n",
      "torch.nn.intrinsic.qat.modules \n",
      "torch.nn.intrinsic.qat.modules.conv_fused - Intrinsic QAT Modules.\n",
      "torch.nn.intrinsic.qat.modules.linear_fused - Intrinsic QAT Modules.\n",
      "torch.nn.intrinsic.qat.modules.linear_relu - Intrinsic QAT Modules.\n",
      "torch.nn.intrinsic.quantized \n",
      "torch.nn.intrinsic.quantized.dynamic \n",
      "torch.nn.intrinsic.quantized.dynamic.modules \n",
      "torch.nn.intrinsic.quantized.dynamic.modules.linear_relu \n",
      "torch.nn.intrinsic.quantized.modules \n",
      "torch.nn.intrinsic.quantized.modules.bn_relu \n",
      "torch.nn.intrinsic.quantized.modules.conv_relu \n",
      "torch.nn.intrinsic.quantized.modules.linear_relu \n",
      "torch.nn.modules \n",
      "torch.nn.modules._functions \n",
      "torch.nn.modules.activation \n",
      "torch.nn.modules.adaptive \n",
      "torch.nn.modules.batchnorm \n",
      "torch.nn.modules.channelshuffle \n",
      "torch.nn.modules.container \n",
      "torch.nn.modules.conv \n",
      "torch.nn.modules.distance \n",
      "torch.nn.modules.dropout \n",
      "torch.nn.modules.flatten \n",
      "torch.nn.modules.fold \n",
      "torch.nn.modules.instancenorm \n",
      "torch.nn.modules.lazy \n",
      "torch.nn.modules.linear \n",
      "torch.nn.modules.loss \n",
      "torch.nn.modules.module \n",
      "torch.nn.modules.normalization \n",
      "torch.nn.modules.padding \n",
      "torch.nn.modules.pixelshuffle \n",
      "torch.nn.modules.pooling \n",
      "torch.nn.modules.rnn \n",
      "torch.nn.modules.sparse \n",
      "torch.nn.modules.transformer \n",
      "torch.nn.modules.upsampling \n",
      "torch.nn.modules.utils \n",
      "torch.nn.parallel \n",
      "torch.nn.parallel._functions \n",
      "torch.nn.parallel.comm \n",
      "torch.nn.parallel.data_parallel \n",
      "torch.nn.parallel.distributed \n",
      "torch.nn.parallel.parallel_apply \n",
      "torch.nn.parallel.replicate \n",
      "torch.nn.parallel.scatter_gather \n",
      "torch.nn.parameter \n",
      "torch.nn.qat - QAT Dynamic Modules.\n",
      "torch.nn.qat.dynamic - QAT Dynamic Modules.\n",
      "torch.nn.qat.dynamic.modules \n",
      "torch.nn.qat.dynamic.modules.linear - QAT Modules.\n",
      "torch.nn.qat.modules - QAT Modules.\n",
      "torch.nn.qat.modules.conv - QAT Modules.\n",
      "torch.nn.qat.modules.embedding_ops - QAT Modules.\n",
      "torch.nn.qat.modules.linear - QAT Modules.\n",
      "torch.nn.quantizable \n",
      "torch.nn.quantizable.modules \n",
      "torch.nn.quantizable.modules.activation - Quantizable Modules.\n",
      "torch.nn.quantizable.modules.rnn - Quantizable Modules.\n",
      "torch.nn.quantized \n",
      "torch.nn.quantized._reference \n",
      "torch.nn.quantized._reference.modules - Quantized Reference Modules.\n",
      "torch.nn.quantized._reference.modules.conv - Quantized Reference Modules.\n",
      "torch.nn.quantized._reference.modules.linear - Quantized Reference Modules.\n",
      "torch.nn.quantized._reference.modules.rnn - Quantized Reference Modules.\n",
      "torch.nn.quantized._reference.modules.sparse - Quantized Reference Modules.\n",
      "torch.nn.quantized._reference.modules.utils - Quantized Reference Modules.\n",
      "torch.nn.quantized.dynamic \n",
      "torch.nn.quantized.dynamic.modules - Quantized Dynamic Modules.\n",
      "torch.nn.quantized.dynamic.modules.conv - Quantized Dynamic Modules.\n",
      "torch.nn.quantized.dynamic.modules.linear - Quantized Dynamic Modules.\n",
      "torch.nn.quantized.dynamic.modules.rnn - Quantized Dynamic Modules.\n",
      "torch.nn.quantized.functional - nn.quantized.functional.\n",
      "torch.nn.quantized.modules - Quantized Modules.\n",
      "torch.nn.quantized.modules.activation - Quantized Modules.\n",
      "torch.nn.quantized.modules.batchnorm - Quantized Modules.\n",
      "torch.nn.quantized.modules.conv - Quantized Modules.\n",
      "torch.nn.quantized.modules.dropout - Quantized Modules.\n",
      "torch.nn.quantized.modules.embedding_ops - Quantized Modules.\n",
      "torch.nn.quantized.modules.functional_modules - Quantized Modules.\n",
      "torch.nn.quantized.modules.linear - Quantized Modules.\n",
      "torch.nn.quantized.modules.normalization - Quantized Modules.\n",
      "torch.nn.quantized.modules.rnn - Quantized Modules.\n",
      "torch.nn.quantized.modules.utils - Quantized Modules.\n",
      "torch.nn.utils \n",
      "torch.nn.utils._deprecation_utils \n",
      "torch.nn.utils._expanded_weights \n",
      "torch.nn.utils._expanded_weights.conv_expanded_weights \n",
      "torch.nn.utils._expanded_weights.conv_utils \n",
      "torch.nn.utils._expanded_weights.embedding_expanded_weights \n",
      "torch.nn.utils._expanded_weights.expanded_weights_impl \n",
      "torch.nn.utils._expanded_weights.expanded_weights_utils \n",
      "torch.nn.utils._expanded_weights.group_norm_expanded_weights \n",
      "torch.nn.utils._expanded_weights.instance_norm_expanded_weights \n",
      "torch.nn.utils._expanded_weights.layer_norm_expanded_weights \n",
      "torch.nn.utils._expanded_weights.linear_expanded_weights \n",
      "torch.nn.utils._named_member_accessor \n",
      "torch.nn.utils._per_sample_grad \n",
      "torch.nn.utils.clip_grad \n",
      "torch.nn.utils.convert_parameters \n",
      "torch.nn.utils.fusion \n",
      "torch.nn.utils.init \n",
      "torch.nn.utils.memory_format \n",
      "torch.nn.utils.parametrizations \n",
      "torch.nn.utils.parametrize \n",
      "torch.nn.utils.prune - Pruning methods.\n",
      "torch.nn.utils.rnn \n",
      "torch.nn.utils.spectral_norm - Spectral Normalization from https://arxiv.org/abs/1802.05957.\n",
      "torch.nn.utils.stateless \n",
      "torch.nn.utils.weight_norm - Weight Normalization from https://arxiv.org/abs/1602.07868.\n",
      "torch.onnx \n",
      "torch.onnx._constants - Constant values used in ONNX.\n",
      "torch.onnx._deprecation - Utility for deprecating functions.\n",
      "torch.onnx._experimental - Experimental classes and functions used by ONNX export.\n",
      "torch.onnx._exporter_states \n",
      "torch.onnx._globals - Globals used internally by the ONNX exporter.\n",
      "torch.onnx._internal \n",
      "torch.onnx._internal._beartype - An internal wrapper for the beartype library.\n",
      "torch.onnx._internal.diagnostics \n",
      "torch.onnx._internal.diagnostics._diagnostic - Diagnostic components for TorchScript based ONNX export, i.e. `torch.onnx.export`.\n",
      "torch.onnx._internal.diagnostics._rules - GENERATED CODE - DO NOT EDIT DIRECTLY\n",
      "torch.onnx._internal.diagnostics.infra \n",
      "torch.onnx._internal.diagnostics.infra._infra - This file defines an additional layer of abstraction on top of the SARIF OM.\n",
      "torch.onnx._internal.diagnostics.infra.context - A diagnostic context based on SARIF.\n",
      "torch.onnx._internal.diagnostics.infra.decorator \n",
      "torch.onnx._internal.diagnostics.infra.formatter \n",
      "torch.onnx._internal.diagnostics.infra.sarif \n",
      "torch.onnx._internal.diagnostics.infra.sarif._address \n",
      "torch.onnx._internal.diagnostics.infra.sarif._artifact \n",
      "torch.onnx._internal.diagnostics.infra.sarif._artifact_change \n",
      "torch.onnx._internal.diagnostics.infra.sarif._artifact_content \n",
      "torch.onnx._internal.diagnostics.infra.sarif._artifact_location \n",
      "torch.onnx._internal.diagnostics.infra.sarif._attachment \n",
      "torch.onnx._internal.diagnostics.infra.sarif._code_flow \n",
      "torch.onnx._internal.diagnostics.infra.sarif._configuration_override \n",
      "torch.onnx._internal.diagnostics.infra.sarif._conversion \n",
      "torch.onnx._internal.diagnostics.infra.sarif._edge \n",
      "torch.onnx._internal.diagnostics.infra.sarif._edge_traversal \n",
      "torch.onnx._internal.diagnostics.infra.sarif._exception \n",
      "torch.onnx._internal.diagnostics.infra.sarif._external_properties \n",
      "torch.onnx._internal.diagnostics.infra.sarif._external_property_file_reference \n",
      "torch.onnx._internal.diagnostics.infra.sarif._external_property_file_references \n",
      "torch.onnx._internal.diagnostics.infra.sarif._fix \n",
      "torch.onnx._internal.diagnostics.infra.sarif._graph \n",
      "torch.onnx._internal.diagnostics.infra.sarif._graph_traversal \n",
      "torch.onnx._internal.diagnostics.infra.sarif._invocation \n",
      "torch.onnx._internal.diagnostics.infra.sarif._location \n",
      "torch.onnx._internal.diagnostics.infra.sarif._location_relationship \n",
      "torch.onnx._internal.diagnostics.infra.sarif._logical_location \n",
      "torch.onnx._internal.diagnostics.infra.sarif._message \n",
      "torch.onnx._internal.diagnostics.infra.sarif._multiformat_message_string \n",
      "torch.onnx._internal.diagnostics.infra.sarif._node \n",
      "torch.onnx._internal.diagnostics.infra.sarif._notification \n",
      "torch.onnx._internal.diagnostics.infra.sarif._physical_location \n",
      "torch.onnx._internal.diagnostics.infra.sarif._property_bag \n",
      "torch.onnx._internal.diagnostics.infra.sarif._rectangle \n",
      "torch.onnx._internal.diagnostics.infra.sarif._region \n",
      "torch.onnx._internal.diagnostics.infra.sarif._replacement \n",
      "torch.onnx._internal.diagnostics.infra.sarif._reporting_configuration \n",
      "torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor \n",
      "torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_reference \n",
      "torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_relationship \n",
      "torch.onnx._internal.diagnostics.infra.sarif._result \n",
      "torch.onnx._internal.diagnostics.infra.sarif._result_provenance \n",
      "torch.onnx._internal.diagnostics.infra.sarif._run \n",
      "torch.onnx._internal.diagnostics.infra.sarif._run_automation_details \n",
      "torch.onnx._internal.diagnostics.infra.sarif._sarif_log \n",
      "torch.onnx._internal.diagnostics.infra.sarif._special_locations \n",
      "torch.onnx._internal.diagnostics.infra.sarif._stack \n",
      "torch.onnx._internal.diagnostics.infra.sarif._stack_frame \n",
      "torch.onnx._internal.diagnostics.infra.sarif._suppression \n",
      "torch.onnx._internal.diagnostics.infra.sarif._thread_flow \n",
      "torch.onnx._internal.diagnostics.infra.sarif._thread_flow_location \n",
      "torch.onnx._internal.diagnostics.infra.sarif._tool \n",
      "torch.onnx._internal.diagnostics.infra.sarif._tool_component \n",
      "torch.onnx._internal.diagnostics.infra.sarif._tool_component_reference \n",
      "torch.onnx._internal.diagnostics.infra.sarif._translation_metadata \n",
      "torch.onnx._internal.diagnostics.infra.sarif._version_control_details \n",
      "torch.onnx._internal.diagnostics.infra.sarif._web_request \n",
      "torch.onnx._internal.diagnostics.infra.sarif._web_response \n",
      "torch.onnx._internal.diagnostics.infra.sarif.version \n",
      "torch.onnx._internal.diagnostics.infra.utils \n",
      "torch.onnx._internal.exporter \n",
      "torch.onnx._internal.fx \n",
      "torch.onnx._internal.fx._pass \n",
      "torch.onnx._internal.fx.analysis \n",
      "torch.onnx._internal.fx.decomposition_skip - A context manager that disables the decomposition of certain ops during dynamo tracing.\n",
      "torch.onnx._internal.fx.decomposition_table - Dispatcher for AtenLib functions from onnx-script.\n",
      "torch.onnx._internal.fx.diagnostics \n",
      "torch.onnx._internal.fx.dynamo_graph_extractor \n",
      "torch.onnx._internal.fx.fx_onnx_interpreter \n",
      "torch.onnx._internal.fx.fx_symbolic_graph_extractor \n",
      "torch.onnx._internal.fx.onnxfunction_dispatcher - Dispatcher for AtenLib functions from onnx-script.\n",
      "torch.onnx._internal.fx.op_validation - Module for handling op-level validation during exporting.\n",
      "torch.onnx._internal.fx.passes \n",
      "torch.onnx._internal.fx.patcher \n",
      "torch.onnx._internal.fx.registration - Module for handling ATen to ONNX functions registration.\n",
      "torch.onnx._internal.fx.serialization \n",
      "torch.onnx._internal.fx.torch_export_graph_extractor \n",
      "torch.onnx._internal.fx.type_utils - Utilities for converting and operating on ONNX, JIT and torch types.\n",
      "torch.onnx._internal.io_adapter \n",
      "torch.onnx._internal.jit_utils - Utilities for manipulating the torch.Graph object and the torchscript.\n",
      "torch.onnx._internal.onnx_proto_utils - Utilities for manipulating the onnx and onnx-script dependencies and ONNX proto.\n",
      "torch.onnx._internal.onnxruntime \n",
      "torch.onnx._internal.registration - Module for handling symbolic function registration.\n",
      "torch.onnx._onnx_supported_ops \n",
      "torch.onnx._type_utils - Utilities for converting and operating on ONNX, JIT and torch types.\n",
      "torch.onnx.errors - ONNX exporter exceptions.\n",
      "torch.onnx.operators - This file provides a location for operators that help exporting models via onnx.\n",
      "torch.onnx.symbolic_caffe2 \n",
      "torch.onnx.symbolic_helper \n",
      "torch.onnx.symbolic_opset10 \n",
      "torch.onnx.symbolic_opset11 - This file exports ONNX ops for opset 11.\n",
      "torch.onnx.symbolic_opset12 \n",
      "torch.onnx.symbolic_opset13 \n",
      "torch.onnx.symbolic_opset14 - This file exports ONNX ops for opset 14.\n",
      "torch.onnx.symbolic_opset15 - This file exports ONNX ops for opset 15.\n",
      "torch.onnx.symbolic_opset16 - This file exports ONNX ops for opset 16.\n",
      "torch.onnx.symbolic_opset17 - This file exports ONNX ops for opset 17.\n",
      "torch.onnx.symbolic_opset18 - This file exports ONNX ops for opset 18.\n",
      "torch.onnx.symbolic_opset7 - Note [ONNX operators that are added/updated from opset 7 to opset 8]\n",
      "torch.onnx.symbolic_opset8 - Note [ONNX operators that are added/updated from opset 8 to opset 9]\n",
      "torch.onnx.symbolic_opset9 - This file exports ONNX ops for opset 9.\n",
      "torch.onnx.utils - Functions to export models into the ONNX IR format.\n",
      "torch.onnx.verification - Functions to verify exported ONNX model is functionally equivalent to original PyTorch model.\n",
      "torch.optim - :mod:`torch.optim` is a package implementing various optimization algorithms.\n",
      "torch.optim._functional - Functional interface.\n",
      "torch.optim._multi_tensor - :mod:`torch.optim._multi_tensor` is a package implementing various optimization algorithms.\n",
      "torch.optim.adadelta \n",
      "torch.optim.adagrad \n",
      "torch.optim.adam \n",
      "torch.optim.adamax \n",
      "torch.optim.adamw \n",
      "torch.optim.asgd \n",
      "torch.optim.lbfgs \n",
      "torch.optim.lr_scheduler \n",
      "torch.optim.nadam \n",
      "torch.optim.optimizer \n",
      "torch.optim.radam \n",
      "torch.optim.rmsprop \n",
      "torch.optim.rprop \n",
      "torch.optim.sgd \n",
      "torch.optim.sparse_adam \n",
      "torch.optim.swa_utils \n",
      "torch.overrides - Python implementation of ``__torch_function__``\n",
      "torch.package \n",
      "torch.package._digraph \n",
      "torch.package._directory_reader \n",
      "torch.package._importlib \n",
      "torch.package._mangling - Import mangling.\n",
      "torch.package._mock \n",
      "torch.package._package_pickler - isort:skip_file\n",
      "torch.package._package_unpickler \n",
      "torch.package._stdlib - List of Python standard library modules.\n",
      "torch.package.analyze \n",
      "torch.package.analyze.find_first_use_of_broken_modules \n",
      "torch.package.analyze.is_from_package \n",
      "torch.package.analyze.trace_dependencies \n",
      "torch.package.file_structure_representation \n",
      "torch.package.find_file_dependencies \n",
      "torch.package.glob_group \n",
      "torch.package.importer \n",
      "torch.package.package_exporter \n",
      "torch.package.package_importer \n",
      "torch.profiler - PyTorch Profiler is a tool that allows the collection of performance metrics during training and inference.\n",
      "torch.profiler._memory_profiler \n",
      "torch.profiler._pattern_matcher \n",
      "torch.profiler._utils \n",
      "torch.profiler.itt \n",
      "torch.profiler.profiler \n",
      "torch.profiler.python_tracer \n",
      "torch.quantization \n",
      "torch.quantization._numeric_suite - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization._numeric_suite_fx - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization._quantized_conversions \n",
      "torch.quantization.fake_quantize - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fuse_modules - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fuser_method_mappings - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx._equalize - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.convert - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.fuse - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.fusion_patterns - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.graph_module - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.match_utils - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.pattern_utils - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.prepare - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.quantization_patterns - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.quantization_types - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.fx.utils - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.observer - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.qconfig - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.quant_type - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.quantization_mappings - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.quantize - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.quantize_fx - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.quantize_jit - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.stubs - This file is in the process of migration to `torch/ao/quantization`, and\n",
      "torch.quantization.utils - Utils shared by different modes of quantization (eager/graph)\n",
      "torch.quasirandom \n",
      "torch.random \n",
      "torch.return_types \n",
      "torch.serialization \n",
      "torch.signal \n",
      "torch.signal.windows \n",
      "torch.signal.windows.windows \n",
      "torch.sparse \n",
      "torch.sparse._semi_structured_conversions \n",
      "torch.sparse._semi_structured_ops \n",
      "torch.sparse._triton_ops \n",
      "torch.sparse._triton_ops_meta - Provides optimal triton kernel parameters.\n",
      "torch.sparse.semi_structured \n",
      "torch.special \n",
      "torch.storage \n",
      "torch.testing \n",
      "torch.testing._comparison \n",
      "torch.testing._creation - This module contains tensor creation utilities.\n",
      "torch.testing._internal \n",
      "torch.testing._internal.autocast_test_lists \n",
      "torch.testing._internal.autograd_function_db \n",
      "torch.testing._internal.check_kernel_launches \n",
      "torch.testing._internal.codegen \n",
      "torch.testing._internal.common_cuda - This file is allowed to initialize CUDA context when imported.\n",
      "torch.testing._internal.common_device_type \n",
      "torch.testing._internal.common_dist_composable \n",
      "torch.testing._internal.common_distributed \n",
      "torch.testing._internal.common_dtype \n",
      "torch.testing._internal.common_fsdp \n",
      "torch.testing._internal.common_jit \n",
      "torch.testing._internal.common_methods_invocations \n",
      "torch.testing._internal.common_mkldnn \n",
      "torch.testing._internal.common_modules \n",
      "torch.testing._internal.common_nn \n",
      "torch.testing._internal.common_optimizers \n",
      "torch.testing._internal.common_pruning \n",
      "torch.testing._internal.common_quantization - Importing this file includes common utility methods and base clases for\n",
      "torch.testing._internal.common_quantized - Importing this file includes common utility methods for checking quantized\n",
      "torch.testing._internal.common_subclass \n",
      "torch.testing._internal.common_utils - Importing this file must **not** initialize CUDA context. test_distributed\n",
      "torch.testing._internal.composite_compliance \n",
      "torch.testing._internal.control_flow_opinfo_db \n",
      "torch.testing._internal.custom_op_db \n",
      "torch.testing._internal.data \n",
      "torch.testing._internal.data.network1 \n",
      "torch.testing._internal.data.network2 \n",
      "torch.testing._internal.dist_utils \n",
      "torch.testing._internal.distributed \n",
      "torch.testing._internal.distributed._shard \n",
      "torch.testing._internal.distributed._shard.sharded_tensor \n",
      "torch.testing._internal.distributed._shard.test_common \n",
      "torch.testing._internal.distributed._tensor \n",
      "torch.testing._internal.distributed._tensor.common_dtensor \n",
      "torch.testing._internal.distributed.checkpoint_utils \n",
      "torch.testing._internal.distributed.common_state_dict \n",
      "torch.testing._internal.distributed.ddp_under_dist_autograd_test \n",
      "torch.testing._internal.distributed.distributed_test \n",
      "torch.testing._internal.distributed.distributed_utils \n",
      "torch.testing._internal.distributed.fake_pg \n",
      "torch.testing._internal.distributed.multi_threaded_pg \n",
      "torch.testing._internal.distributed.nn \n",
      "torch.testing._internal.distributed.nn.api \n",
      "torch.testing._internal.distributed.nn.api.remote_module_test \n",
      "torch.testing._internal.distributed.pipe_with_ddp_test \n",
      "torch.testing._internal.distributed.pipeline \n",
      "torch.testing._internal.distributed.rpc \n",
      "torch.testing._internal.distributed.rpc.dist_autograd_test \n",
      "torch.testing._internal.distributed.rpc.dist_optimizer_test \n",
      "torch.testing._internal.distributed.rpc.examples \n",
      "torch.testing._internal.distributed.rpc.examples.parameter_server_test \n",
      "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test \n",
      "torch.testing._internal.distributed.rpc.faulty_agent_rpc_test \n",
      "torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture \n",
      "torch.testing._internal.distributed.rpc.jit \n",
      "torch.testing._internal.distributed.rpc.jit.dist_autograd_test \n",
      "torch.testing._internal.distributed.rpc.jit.rpc_test \n",
      "torch.testing._internal.distributed.rpc.jit.rpc_test_faulty \n",
      "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture \n",
      "torch.testing._internal.distributed.rpc.rpc_test \n",
      "torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture \n",
      "torch.testing._internal.distributed.rpc_utils \n",
      "torch.testing._internal.dynamo_test_failures \n",
      "torch.testing._internal.generated \n",
      "torch.testing._internal.generated.annotated_fn_args - This file is needed for generating procedural tests required for\n",
      "torch.testing._internal.hypothesis_utils \n",
      "torch.testing._internal.inductor_utils \n",
      "torch.testing._internal.jit_metaprogramming_utils \n",
      "torch.testing._internal.jit_utils \n",
      "torch.testing._internal.logging_tensor \n",
      "torch.testing._internal.logging_utils \n",
      "torch.testing._internal.opinfo \n",
      "torch.testing._internal.optests \n",
      "torch.testing._internal.quantization_torch_package_models \n",
      "torch.testing._internal.static_module \n",
      "torch.testing._internal.test_module \n",
      "torch.testing._internal.test_module.future_div \n",
      "torch.testing._internal.test_module.no_future_div \n",
      "torch.testing._internal.triton_utils \n",
      "torch.testing._internal.two_tensor \n",
      "torch.torch_version \n",
      "torch.types \n",
      "torch.utils \n",
      "torch.utils._config_module \n",
      "torch.utils._content_store \n",
      "torch.utils._contextlib \n",
      "torch.utils._cpp_extension_versioner \n",
      "torch.utils._cuda_trace \n",
      "torch.utils._cxx_pytree - Contains utility functions for working with nested python data structures.\n",
      "torch.utils._device \n",
      "torch.utils._foreach_utils \n",
      "torch.utils._freeze - Freeze Python packages.\n",
      "torch.utils._import_utils \n",
      "torch.utils._mode_utils \n",
      "torch.utils._python_dispatch \n",
      "torch.utils._pytree - Contains utility functions for working with nested python data structures.\n",
      "torch.utils._stats \n",
      "torch.utils._sympy \n",
      "torch.utils._sympy.functions \n",
      "torch.utils._sympy.interp - This is a simple interpreter for Sympy expressions that dispatches to\n",
      "torch.utils._sympy.reference \n",
      "torch.utils._sympy.singleton_int \n",
      "torch.utils._sympy.solve \n",
      "torch.utils._sympy.value_ranges \n",
      "torch.utils._traceback \n",
      "torch.utils._triton \n",
      "torch.utils._typing_utils - Miscellaneous utilities to aid with typing.\n",
      "torch.utils._zip \n",
      "torch.utils.backcompat \n",
      "torch.utils.backend_registration \n",
      "torch.utils.benchmark \n",
      "torch.utils.benchmark.examples \n",
      "torch.utils.benchmark.examples.blas_compare_setup \n",
      "torch.utils.benchmark.examples.compare - Example of Timer and Compare APIs:\n",
      "torch.utils.benchmark.examples.fuzzer - Example of the Timer and Fuzzer APIs:\n",
      "torch.utils.benchmark.examples.op_benchmark - Example use of Timer and op fuzzers to measure kernel performance.\n",
      "torch.utils.benchmark.examples.simple_timeit - Trivial use of Timer API:\n",
      "torch.utils.benchmark.examples.spectral_ops_fuzz_test - Microbenchmarks for the torch.fft module\n",
      "torch.utils.benchmark.op_fuzzers \n",
      "torch.utils.benchmark.op_fuzzers.binary \n",
      "torch.utils.benchmark.op_fuzzers.sparse_binary \n",
      "torch.utils.benchmark.op_fuzzers.sparse_unary \n",
      "torch.utils.benchmark.op_fuzzers.spectral \n",
      "torch.utils.benchmark.op_fuzzers.unary \n",
      "torch.utils.benchmark.utils \n",
      "torch.utils.benchmark.utils._stubs \n",
      "torch.utils.benchmark.utils.common - Base shared classes and utilities.\n",
      "torch.utils.benchmark.utils.compare - Display class to aggregate and print the results of many measurements.\n",
      "torch.utils.benchmark.utils.compile \n",
      "torch.utils.benchmark.utils.cpp_jit - JIT C++ strings into executables.\n",
      "torch.utils.benchmark.utils.fuzzer \n",
      "torch.utils.benchmark.utils.sparse_fuzzer \n",
      "torch.utils.benchmark.utils.timer - Timer class based on the timeit.Timer class, but torch aware.\n",
      "torch.utils.benchmark.utils.valgrind_wrapper \n",
      "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface - Intermediate layer between `Timer` and `valgrind`.\n",
      "torch.utils.bottleneck \n",
      "torch.utils.bottleneck.__main__ \n",
      "torch.utils.bundled_inputs \n",
      "torch.utils.checkpoint \n",
      "torch.utils.collect_env \n",
      "torch.utils.cpp_backtrace \n",
      "torch.utils.cpp_extension \n",
      "torch.utils.data \n",
      "torch.utils.data._utils - Utility classes & functions for data loading. Code in this folder is mostly used by ../dataloder.py.\n",
      "torch.utils.data._utils.collate - Contains definitions of the methods used by the _BaseDataLoaderIter workers.\n",
      "torch.utils.data._utils.fetch - Contains definitions of the methods used by the _BaseDataLoaderIter to fetch data from an iterable-style or map-style dataset.\n",
      "torch.utils.data._utils.pin_memory - Contains definitions of the methods used by the _BaseDataLoaderIter to put fetched tensors into pinned memory.\n",
      "torch.utils.data._utils.signal_handling - Signal handling for multiprocessing data loading.\n",
      "torch.utils.data._utils.worker - \"Contains definitions of the methods used by the _BaseDataLoaderIter workers.\n",
      "torch.utils.data.backward_compatibility \n",
      "torch.utils.data.dataloader - Definition of the DataLoader and associated iterators that subclass _BaseDataLoaderIter.\n",
      "torch.utils.data.datapipes \n",
      "torch.utils.data.datapipes._decorator \n",
      "torch.utils.data.datapipes._hook_iterator \n",
      "torch.utils.data.datapipes._typing \n",
      "torch.utils.data.datapipes.dataframe \n",
      "torch.utils.data.datapipes.dataframe.dataframe_wrapper \n",
      "torch.utils.data.datapipes.dataframe.dataframes \n",
      "torch.utils.data.datapipes.dataframe.datapipes \n",
      "torch.utils.data.datapipes.dataframe.structures \n",
      "torch.utils.data.datapipes.datapipe \n",
      "torch.utils.data.datapipes.gen_pyi \n",
      "torch.utils.data.datapipes.iter \n",
      "torch.utils.data.datapipes.iter.callable \n",
      "torch.utils.data.datapipes.iter.combinatorics \n",
      "torch.utils.data.datapipes.iter.combining \n",
      "torch.utils.data.datapipes.iter.filelister \n",
      "torch.utils.data.datapipes.iter.fileopener \n",
      "torch.utils.data.datapipes.iter.grouping \n",
      "torch.utils.data.datapipes.iter.routeddecoder \n",
      "torch.utils.data.datapipes.iter.selecting \n",
      "torch.utils.data.datapipes.iter.sharding \n",
      "torch.utils.data.datapipes.iter.streamreader \n",
      "torch.utils.data.datapipes.iter.utils \n",
      "torch.utils.data.datapipes.map \n",
      "torch.utils.data.datapipes.map.callable \n",
      "torch.utils.data.datapipes.map.combinatorics \n",
      "torch.utils.data.datapipes.map.combining \n",
      "torch.utils.data.datapipes.map.grouping \n",
      "torch.utils.data.datapipes.map.utils \n",
      "torch.utils.data.datapipes.utils \n",
      "torch.utils.data.datapipes.utils.common \n",
      "torch.utils.data.datapipes.utils.decoder \n",
      "torch.utils.data.datapipes.utils.snapshot \n",
      "torch.utils.data.dataset \n",
      "torch.utils.data.distributed \n",
      "torch.utils.data.graph \n",
      "torch.utils.data.graph_settings \n",
      "torch.utils.data.sampler \n",
      "torch.utils.deterministic \n",
      "torch.utils.dlpack \n",
      "torch.utils.file_baton \n",
      "torch.utils.flop_counter \n",
      "torch.utils.hipify \n",
      "torch.utils.hipify.constants - Constants for annotations in the mapping.\n",
      "torch.utils.hipify.cuda_to_hip_mappings \n",
      "torch.utils.hipify.hipify_python - The Python Hipify script.\n",
      "torch.utils.hipify.version \n",
      "torch.utils.hooks \n",
      "torch.utils.jit \n",
      "torch.utils.jit.log_extract \n",
      "torch.utils.mkldnn \n",
      "torch.utils.mobile_optimizer - This module contains utility method for mobile model optimization and lint.\n",
      "torch.utils.model_dump - model_dump: a one-stop shop for TorchScript model inspection.\n",
      "torch.utils.model_dump.__main__ \n",
      "torch.utils.model_zoo \n",
      "torch.utils.show_pickle \n",
      "torch.utils.tensorboard \n",
      "torch.utils.throughput_benchmark \n",
      "torch.utils.viz \n",
      "torch.utils.viz._cycles \n",
      "torch.utils.weak \n",
      "torch.version \n",
      "torch.xpu - This package introduces support for the XPU backend, specifically tailored for\n",
      "torch.xpu._utils \n",
      "torch.xpu.random \n",
      "torch.xpu.streams \n",
      "torchgen - torchgen\n",
      "torchgen.api \n",
      "torchgen.api.autograd \n",
      "torchgen.api.cpp \n",
      "torchgen.api.dispatcher \n",
      "torchgen.api.functionalization \n",
      "torchgen.api.lazy \n",
      "torchgen.api.meta \n",
      "torchgen.api.native \n",
      "torchgen.api.python \n",
      "torchgen.api.structured \n",
      "torchgen.api.translate \n",
      "torchgen.api.types \n",
      "torchgen.api.types.signatures \n",
      "torchgen.api.types.types - Where should I add a new type? `types_base.py` vs `types.py`\n",
      "torchgen.api.types.types_base - Where should I add a new type? `types_base.py` vs `types.py`\n",
      "torchgen.api.ufunc \n",
      "torchgen.api.unboxing \n",
      "torchgen.code_template \n",
      "torchgen.context \n",
      "torchgen.dest \n",
      "torchgen.dest.lazy_ir \n",
      "torchgen.dest.lazy_ts_lowering \n",
      "torchgen.dest.native_functions \n",
      "torchgen.dest.register_dispatch_key \n",
      "torchgen.dest.ufunc \n",
      "torchgen.executorch \n",
      "torchgen.executorch.api \n",
      "torchgen.executorch.api.custom_ops \n",
      "torchgen.executorch.api.et_cpp \n",
      "torchgen.executorch.api.types \n",
      "torchgen.executorch.api.types.signatures \n",
      "torchgen.executorch.api.types.types \n",
      "torchgen.executorch.api.unboxing \n",
      "torchgen.executorch.model \n",
      "torchgen.executorch.parse \n",
      "torchgen.gen \n",
      "torchgen.gen_aoti_c_shim \n",
      "torchgen.gen_backend_stubs \n",
      "torchgen.gen_executorch \n",
      "torchgen.gen_functionalization_type \n",
      "torchgen.gen_lazy_tensor \n",
      "torchgen.gen_vmap_plumbing \n",
      "torchgen.local \n",
      "torchgen.model \n",
      "torchgen.native_function_generation \n",
      "torchgen.operator_versions \n",
      "torchgen.operator_versions.gen_mobile_upgraders \n",
      "torchgen.operator_versions.gen_mobile_upgraders_constant \n",
      "torchgen.selective_build \n",
      "torchgen.selective_build.operator \n",
      "torchgen.selective_build.selector \n",
      "torchgen.static_runtime \n",
      "torchgen.static_runtime.config \n",
      "torchgen.static_runtime.gen_static_runtime_ops \n",
      "torchgen.static_runtime.generator \n",
      "torchgen.utils \n",
      "torchgen.yaml_utils \n",
      "torchvision \n",
      "torchvision._C \n",
      "torchvision._internally_replaced_utils \n",
      "torchvision._meta_registrations \n",
      "torchvision._utils \n",
      "torchvision.datasets \n",
      "torchvision.datasets._optical_flow \n",
      "torchvision.datasets._stereo_matching \n",
      "torchvision.datasets.caltech \n",
      "torchvision.datasets.celeba \n",
      "torchvision.datasets.cifar \n",
      "torchvision.datasets.cityscapes \n",
      "torchvision.datasets.clevr \n",
      "torchvision.datasets.coco \n",
      "torchvision.datasets.country211 \n",
      "torchvision.datasets.dtd \n",
      "torchvision.datasets.eurosat \n",
      "torchvision.datasets.fakedata \n",
      "torchvision.datasets.fer2013 \n",
      "torchvision.datasets.fgvc_aircraft \n",
      "torchvision.datasets.flickr \n",
      "torchvision.datasets.flowers102 \n",
      "torchvision.datasets.folder \n",
      "torchvision.datasets.food101 \n",
      "torchvision.datasets.gtsrb \n",
      "torchvision.datasets.hmdb51 \n",
      "torchvision.datasets.imagenet \n",
      "torchvision.datasets.imagenette \n",
      "torchvision.datasets.inaturalist \n",
      "torchvision.datasets.kinetics \n",
      "torchvision.datasets.kitti \n",
      "torchvision.datasets.lfw \n",
      "torchvision.datasets.lsun \n",
      "torchvision.datasets.mnist \n",
      "torchvision.datasets.moving_mnist \n",
      "torchvision.datasets.omniglot \n",
      "torchvision.datasets.oxford_iiit_pet \n",
      "torchvision.datasets.pcam \n",
      "torchvision.datasets.phototour \n",
      "torchvision.datasets.places365 \n",
      "torchvision.datasets.rendered_sst2 \n",
      "torchvision.datasets.samplers \n",
      "torchvision.datasets.samplers.clip_sampler \n",
      "torchvision.datasets.sbd \n",
      "torchvision.datasets.sbu \n",
      "torchvision.datasets.semeion \n",
      "torchvision.datasets.stanford_cars \n",
      "torchvision.datasets.stl10 \n",
      "torchvision.datasets.sun397 \n",
      "torchvision.datasets.svhn \n",
      "torchvision.datasets.ucf101 \n",
      "torchvision.datasets.usps \n",
      "torchvision.datasets.utils \n",
      "torchvision.datasets.video_utils \n",
      "torchvision.datasets.vision \n",
      "torchvision.datasets.voc \n",
      "torchvision.datasets.widerface \n",
      "torchvision.extension \n",
      "torchvision.image \n",
      "torchvision.io \n",
      "torchvision.io._load_gpu_decoder \n",
      "torchvision.io._video_opt \n",
      "torchvision.io.image \n",
      "torchvision.io.video \n",
      "torchvision.io.video_reader \n",
      "torchvision.models \n",
      "torchvision.models._api \n",
      "torchvision.models._meta - This file is part of the private API. Please do not refer to any variables defined here directly as they will be\n",
      "torchvision.models._utils \n",
      "torchvision.models.alexnet \n",
      "torchvision.models.convnext \n",
      "torchvision.models.densenet \n",
      "torchvision.models.detection \n",
      "torchvision.models.detection._utils \n",
      "torchvision.models.detection.anchor_utils \n",
      "torchvision.models.detection.backbone_utils \n",
      "torchvision.models.detection.faster_rcnn \n",
      "torchvision.models.detection.fcos \n",
      "torchvision.models.detection.generalized_rcnn - Implements the Generalized R-CNN framework\n",
      "torchvision.models.detection.image_list \n",
      "torchvision.models.detection.keypoint_rcnn \n",
      "torchvision.models.detection.mask_rcnn \n",
      "torchvision.models.detection.retinanet \n",
      "torchvision.models.detection.roi_heads \n",
      "torchvision.models.detection.rpn \n",
      "torchvision.models.detection.ssd \n",
      "torchvision.models.detection.ssdlite \n",
      "torchvision.models.detection.transform \n",
      "torchvision.models.efficientnet \n",
      "torchvision.models.feature_extraction \n",
      "torchvision.models.googlenet \n",
      "torchvision.models.inception \n",
      "torchvision.models.maxvit \n",
      "torchvision.models.mnasnet \n",
      "torchvision.models.mobilenet \n",
      "torchvision.models.mobilenetv2 \n",
      "torchvision.models.mobilenetv3 \n",
      "torchvision.models.optical_flow \n",
      "torchvision.models.optical_flow._utils \n",
      "torchvision.models.optical_flow.raft \n",
      "torchvision.models.quantization \n",
      "torchvision.models.quantization.googlenet \n",
      "torchvision.models.quantization.inception \n",
      "torchvision.models.quantization.mobilenet \n",
      "torchvision.models.quantization.mobilenetv2 \n",
      "torchvision.models.quantization.mobilenetv3 \n",
      "torchvision.models.quantization.resnet \n",
      "torchvision.models.quantization.shufflenetv2 \n",
      "torchvision.models.quantization.utils \n",
      "torchvision.models.regnet \n",
      "torchvision.models.resnet \n",
      "torchvision.models.segmentation \n",
      "torchvision.models.segmentation._utils \n",
      "torchvision.models.segmentation.deeplabv3 \n",
      "torchvision.models.segmentation.fcn \n",
      "torchvision.models.segmentation.lraspp \n",
      "torchvision.models.shufflenetv2 \n",
      "torchvision.models.squeezenet \n",
      "torchvision.models.swin_transformer \n",
      "torchvision.models.vgg \n",
      "torchvision.models.video \n",
      "torchvision.models.video.mvit \n",
      "torchvision.models.video.resnet \n",
      "torchvision.models.video.s3d \n",
      "torchvision.models.video.swin_transformer \n",
      "torchvision.models.vision_transformer \n",
      "torchvision.ops \n",
      "torchvision.ops._box_convert \n",
      "torchvision.ops._register_onnx_ops \n",
      "torchvision.ops._utils \n",
      "torchvision.ops.boxes \n",
      "torchvision.ops.ciou_loss \n",
      "torchvision.ops.deform_conv \n",
      "torchvision.ops.diou_loss \n",
      "torchvision.ops.drop_block \n",
      "torchvision.ops.feature_pyramid_network \n",
      "torchvision.ops.focal_loss \n",
      "torchvision.ops.giou_loss \n",
      "torchvision.ops.misc \n",
      "torchvision.ops.poolers \n",
      "torchvision.ops.ps_roi_align \n",
      "torchvision.ops.ps_roi_pool \n",
      "torchvision.ops.roi_align \n",
      "torchvision.ops.roi_pool \n",
      "torchvision.ops.stochastic_depth \n",
      "torchvision.transforms \n",
      "torchvision.transforms._functional_pil \n",
      "torchvision.transforms._functional_tensor \n",
      "torchvision.transforms._functional_video \n",
      "torchvision.transforms._presets - This file is part of the private API. Please do not use directly these classes as they will be modified on\n",
      "torchvision.transforms._transforms_video \n",
      "torchvision.transforms.autoaugment \n",
      "torchvision.transforms.functional \n",
      "torchvision.transforms.transforms \n",
      "torchvision.transforms.v2 \n",
      "torchvision.transforms.v2._augment \n",
      "torchvision.transforms.v2._auto_augment \n",
      "torchvision.transforms.v2._color \n",
      "torchvision.transforms.v2._container \n",
      "torchvision.transforms.v2._deprecated \n",
      "torchvision.transforms.v2._geometry \n",
      "torchvision.transforms.v2._meta \n",
      "torchvision.transforms.v2._misc \n",
      "torchvision.transforms.v2._temporal \n",
      "torchvision.transforms.v2._transform \n",
      "torchvision.transforms.v2._type_conversion \n",
      "torchvision.transforms.v2._utils \n",
      "torchvision.transforms.v2.functional \n",
      "torchvision.transforms.v2.functional._augment \n",
      "torchvision.transforms.v2.functional._color \n",
      "torchvision.transforms.v2.functional._deprecated \n",
      "torchvision.transforms.v2.functional._geometry \n",
      "torchvision.transforms.v2.functional._meta \n",
      "torchvision.transforms.v2.functional._misc \n",
      "torchvision.transforms.v2.functional._temporal \n",
      "torchvision.transforms.v2.functional._type_conversion \n",
      "torchvision.transforms.v2.functional._utils \n",
      "torchvision.tv_tensors \n",
      "torchvision.tv_tensors._bounding_boxes \n",
      "torchvision.tv_tensors._dataset_wrapper \n",
      "torchvision.tv_tensors._image \n",
      "torchvision.tv_tensors._mask \n",
      "torchvision.tv_tensors._torch_function_helpers \n",
      "torchvision.tv_tensors._tv_tensor \n",
      "torchvision.tv_tensors._video \n",
      "torchvision.utils \n",
      "torchvision.version \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a list of modules whose name contain torch\n",
    "\n",
    "help('modules torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc4aae6-20b5-42f1-af0c-b9dd6f016f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743868242.4477775\n",
      "Sat Apr  5 15:50:42 2025\n"
     ]
    }
   ],
   "source": [
    "# some built in modules - math, random, time, os\n",
    "import time;\n",
    "\n",
    "print(time.time()); # Get current timestamp - no of seconds from 1 Jan 1970 midnight\n",
    "print(time.ctime()); # Get current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4540ea8-9277-4c6b-92da-dddea5b3b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\");\n",
    "time.sleep(5) # delay next statement execution by 5 seconds\n",
    "print(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4afcd72a-3f7b-4d18-bff5-53a0e2f48788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed98a503-46d2-4f9f-9401-6f0c7cd17350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/python'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() # get current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a261557-785f-4c29-a7ab-6f73dd4dde64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['operators.ipynb',\n",
       " 'literals.ipynb',\n",
       " 'variables.ipynb',\n",
       " 'README.md',\n",
       " 'print.ipynb',\n",
       " 'guess_the_number.ipynb',\n",
       " 'data-types.ipynb',\n",
       " 'control_flow.ipynb',\n",
       " 'user-input-and-type-conversion.ipynb',\n",
       " 'built-in-functions.ipynb',\n",
       " 'built-in-modules.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir() # print files in current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d9bee-eb79-4efe-b8bb-64a0695e17b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
